{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1656c2",
   "metadata": {},
   "source": [
    "### Creating 2 combined and standardized feature matrix consisting of Kinematic and EMG Data for each Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589160d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      " PRE-PROCESSING (standardize_offset)\n",
      "========================================================================\n",
      "[DONE] P1: phase1 (168814, 180), phase2 (387674, 180)\n",
      "[DONE] P2: phase1 (183597, 180), phase2 (356604, 180)\n",
      "[DONE] P3: phase1 (134040, 180), phase2 (316406, 180)\n",
      "[DONE] P4: phase1 (138778, 180), phase2 (352780, 180)\n",
      "[DONE] P5: phase1 (219915, 180), phase2 (362094, 180)\n",
      "[DONE] P6: phase1 (167439, 180), phase2 (320959, 180)\n",
      "[DONE] P7: phase1 (134506, 180), phase2 (294965, 180)\n",
      "[DONE] P8: phase1 (145986, 180), phase2 (392938, 180)\n",
      "=== PRE-PROCESSING COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pre-process the multi-modal dataset into phase-specific matrices\n",
    "with standardization (Z-score) and a positive offset.\n",
    "\n",
    "Rationale\n",
    "---------\n",
    "1. *Standardization (Z-score)*: Every channel is scaled to have a mean\n",
    "   of 0 and a standard deviation of 1. This ensures that every channel,\n",
    "   regardless of its original magnitude or variance, has equal weight\n",
    "   in the MMF/NMF cost function.\n",
    "2. *Positive Offset*: A constant is added to the muscle data channels\n",
    "   (OTB and Myo) to shift the minimum value to 0, satisfying the\n",
    "   non-negativity constraint required for NMF.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# =====================================================================\n",
    "# Global parameters\n",
    "# =====================================================================\n",
    "BASE_DIR: Path | str = (\n",
    "    r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\Masterthesis\\Experimental Data\"\n",
    ")\n",
    "PARTICIPANTS: list[int] = list(range(1, 9))\n",
    "PHASES: list[str] = [\"phase1\", \"phase2\"]\n",
    "N_POSE_COLUMNS: int = 6      # Pose columns at the tail of kinematics array\n",
    "DTYPE_WORK: np.dtype = np.float32\n",
    "\n",
    "# =====================================================================\n",
    "# Scaling switches\n",
    "# =====================================================================\n",
    "# ✅ Set to \"standardize_offset\" to use the new scaling approach.\n",
    "FEATURE_SCALE_MODE: str = \"standardize_offset\" # \"standardize_offset\" | \"column_then_block\" | ...\n",
    "# ‼ This flag is only used by the \"column_then_block\" mode.\n",
    "BLOCK_EQUALISE: bool = True\n",
    "\n",
    "# =====================================================================\n",
    "# Scaling helpers\n",
    "# =====================================================================\n",
    "def scale_by_standardize_and_offset(\n",
    "    X: np.ndarray,\n",
    "    idx: dict,\n",
    "    dtype: np.dtype = np.float32,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"✅ Scales all features by Z-score and applies a positive offset\n",
    "    to muscle channels.\n",
    "\n",
    "    1) Standardize (Z-score) all columns to mean=0, std=1.\n",
    "    2) For muscle data blocks (OTB, Myo), shift the data so that the\n",
    "       minimum value is 0 to satisfy non-negativity constraints.\n",
    "    \"\"\"\n",
    "    Xs = X.astype(dtype, copy=True)\n",
    "\n",
    "    # ---------- Step 1: Standardize all columns -----------------------\n",
    "    mean = np.mean(Xs, axis=0)\n",
    "    std = np.std(Xs, axis=0)\n",
    "    std[std == 0] = 1.0  # Avoid division by zero\n",
    "    Xs = (Xs - mean) / std\n",
    "\n",
    "    # ---------- Step 2: Apply positive offset to muscle data ----------\n",
    "    for key in (\"otb_indices\", \"myo_indices\"):\n",
    "        if key not in idx or idx[key] is None:\n",
    "            continue\n",
    "        s, e = idx[key]\n",
    "        if e <= s:\n",
    "            continue\n",
    "        \n",
    "        muscle_block = Xs[:, s:e]\n",
    "        min_val = np.min(muscle_block)\n",
    "\n",
    "        # Shift the entire block so the minimum value becomes 0\n",
    "        if min_val < 0:\n",
    "            Xs[:, s:e] = muscle_block - min_val\n",
    "\n",
    "    return Xs\n",
    "\n",
    "\n",
    "def scale_by_column_rms(\n",
    "    X: np.ndarray,\n",
    "    idx: dict,\n",
    "    block_equalise: bool = True,\n",
    "    dtype: np.dtype = np.float32,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Alternative two-stage scaling: Column RMS then optional Block Equalisation.\n",
    "    \"\"\"\n",
    "    Xs = X.astype(dtype, copy=True)\n",
    "\n",
    "    # ---------- Step 1: per-feature RMS ---------------------------------\n",
    "    rms = np.linalg.norm(Xs, axis=0) / np.sqrt(len(Xs))  # column RMS\n",
    "    rms[rms == 0] = 1.0                                     # avoid div/0\n",
    "    Xs /= rms                                               # broadcasted divide\n",
    "\n",
    "    # ---------- Step 2: equalise block energies --------------------------\n",
    "    if block_equalise:\n",
    "        energies = []\n",
    "        for key in (\"otb_indices\", \"myo_indices\", \"kin_hand_indices\"):\n",
    "            if key not in idx or idx[key] is None:\n",
    "                continue\n",
    "            s, e = idx[key]\n",
    "            energies.append(np.linalg.norm(Xs[:, s:e], ord=\"fro\") ** 2)\n",
    "        if energies:                                        # at least one block\n",
    "            E_ref = float(np.mean(energies))\n",
    "            for key in (\"otb_indices\", \"myo_indices\", \"kin_hand_indices\"):\n",
    "                if key not in idx or idx[key] is None:\n",
    "                    continue\n",
    "                s, e = idx[key]\n",
    "                E_block = np.linalg.norm(Xs[:, s:e], ord=\"fro\") ** 2\n",
    "                if E_block > 0:\n",
    "                    Xs[:, s:e] *= np.sqrt(E_ref / E_block)\n",
    "    return Xs\n",
    "\n",
    "# =====================================================================\n",
    "# I/O helpers\n",
    "# =====================================================================\n",
    "def load_full_phase(\n",
    "    part_dir: Path | str,\n",
    "    trial: int,\n",
    "    phase: str,\n",
    "    n_pose_cols: int,\n",
    ") -> dict | None:\n",
    "    \"\"\"Read uncropped OTB, Myo and hand-only kinematics; return combined\n",
    "    matrix & column indices, or *None* if files are missing/invalid.\"\"\"\n",
    "    sync_dir = Path(part_dir, \"Synchronized Data split in Phases\")\n",
    "    kin_f = sync_dir / f\"match_{trial:02d}_{phase}_kin_norm.npy\"\n",
    "    myo_f = sync_dir / f\"match_{trial:02d}_{phase}_myo.npy\"\n",
    "    otb_f = sync_dir / f\"match_{trial:02d}_{phase}_otb.npy\"\n",
    "    if not (kin_f.exists() and myo_f.exists() and otb_f.exists()):\n",
    "        return None\n",
    "\n",
    "    kin, myo, otb = map(np.load, (kin_f, myo_f, otb_f))\n",
    "    T = min(len(kin), len(myo), len(otb))\n",
    "    if T < 5 or kin.shape[1] <= n_pose_cols:\n",
    "        return None\n",
    "\n",
    "    kin_h = kin[:T, : kin.shape[1] - n_pose_cols]  # drop pose cols\n",
    "    X = np.hstack([otb[:T], myo[:T], kin_h])\n",
    "\n",
    "    otb_end = otb.shape[1]\n",
    "    myo_end = otb_end + myo.shape[1]\n",
    "    kin_end = myo_end + kin_h.shape[1]\n",
    "\n",
    "    return {\n",
    "        \"combined\": X,\n",
    "        \"otb_indices\": (0, otb_end),\n",
    "        \"myo_indices\": (otb_end, myo_end),\n",
    "        \"kin_hand_indices\": (myo_end, kin_end),\n",
    "    }\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Main processing loop\n",
    "# =====================================================================\n",
    "def preprocess_and_save_all_data() -> None:\n",
    "    bar = \"=\" * 72\n",
    "    print(f\"\\n{bar}\\n PRE-PROCESSING ({FEATURE_SCALE_MODE})\\n{bar}\")\n",
    "\n",
    "    for pid in PARTICIPANTS:\n",
    "        p_dir = Path(BASE_DIR, f\"P({pid})\")\n",
    "        if not p_dir.is_dir():\n",
    "            print(f\"[WARN] folder missing for P{pid}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        data_phase: dict[str, list[np.ndarray]] = {ph: [] for ph in PHASES}\n",
    "        len_phase: dict[str, list[int]] = {ph: [] for ph in PHASES}\n",
    "        last_idx: dict | None = None\n",
    "\n",
    "        # --------- load all trials -----------------------------------\n",
    "        for trial in range(1, 25):\n",
    "            for ph in PHASES:\n",
    "                out = load_full_phase(p_dir, trial, ph, N_POSE_COLUMNS)\n",
    "                if out is None:\n",
    "                    continue\n",
    "                data_phase[ph].append(out[\"combined\"])\n",
    "                len_phase[ph].append(out[\"combined\"].shape[0])\n",
    "                last_idx = out                              # store mapping\n",
    "\n",
    "        if any(len(data_phase[ph]) == 0 for ph in PHASES):\n",
    "            print(f\"[WARN] P{pid}: no valid data for one phase, skipping.\")\n",
    "            continue\n",
    "        assert last_idx is not None, \"Index mapping not captured.\"\n",
    "\n",
    "        # --------- stack trials per phase ---------------------------\n",
    "        X1 = np.vstack(data_phase[\"phase1\"], dtype=DTYPE_WORK)\n",
    "        X2 = np.vstack(data_phase[\"phase2\"], dtype=DTYPE_WORK)\n",
    "\n",
    "        # --------- scaling ------------------------------------------\n",
    "        if FEATURE_SCALE_MODE == \"standardize_offset\":\n",
    "            X1s = scale_by_standardize_and_offset(X1, last_idx)\n",
    "            X2s = scale_by_standardize_and_offset(X2, last_idx)\n",
    "\n",
    "        elif FEATURE_SCALE_MODE == \"column_then_block\":\n",
    "            X1s = scale_by_column_rms(X1, last_idx, BLOCK_EQUALISE)\n",
    "            X2s = scale_by_column_rms(X2, last_idx, BLOCK_EQUALISE)\n",
    "\n",
    "        else:\n",
    "            # Added other legacy modes back for completeness\n",
    "            legacy_modes = {\n",
    "                \"feature\": scale_each_feature_rms,\n",
    "                \"block\": scale_blocks_by_rms,\n",
    "            }\n",
    "            if FEATURE_SCALE_MODE in legacy_modes:\n",
    "                 # Note: Legacy modes don't use the idx mapping in this simplified call\n",
    "                 X1s = legacy_modes[FEATURE_SCALE_MODE](X1) if FEATURE_SCALE_MODE == \"feature\" else legacy_modes[FEATURE_SCALE_MODE](X1, last_idx)\n",
    "                 X2s = legacy_modes[FEATURE_SCALE_MODE](X2) if FEATURE_SCALE_MODE == \"feature\" else legacy_modes[FEATURE_SCALE_MODE](X2, last_idx)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid FEATURE_SCALE_MODE: '{FEATURE_SCALE_MODE}'. \"\n",
    "                    \"Must be 'standardize_offset', 'column_then_block', 'feature', or 'block'\"\n",
    "                )\n",
    "\n",
    "\n",
    "        # --------- persist ------------------------------------------\n",
    "        out_dir = Path(p_dir, \"Preprocessed_Data_Matrix\")\n",
    "        out_dir.mkdir(exist_ok=True)\n",
    "        np.save(out_dir / f\"P{pid}_combined_matrix_phase1.npy\", X1s)\n",
    "        np.save(out_dir / f\"P{pid}_combined_matrix_phase2.npy\", X2s)\n",
    "\n",
    "        if 'combined' in last_idx:\n",
    "            del last_idx['combined']\n",
    "\n",
    "        meta = dict(last_idx)\n",
    "        meta[\"scaling\"] = {\n",
    "            \"feature_scale_mode\": FEATURE_SCALE_MODE,\n",
    "            \"block_equalise\": (\n",
    "                BLOCK_EQUALISE if \"column\" in FEATURE_SCALE_MODE else \"N/A\"\n",
    "            ),\n",
    "        }\n",
    "        meta[\"phase1_trial_lengths\"] = len_phase[\"phase1\"]\n",
    "        meta[\"phase2_trial_lengths\"] = len_phase[\"phase2\"]\n",
    "        joblib.dump(meta, out_dir / f\"P{pid}_feature_indices.joblib\")\n",
    "\n",
    "        print(f\"[DONE] P{pid}: phase1 {X1s.shape}, phase2 {X2s.shape}\")\n",
    "\n",
    "    print(\"=== PRE-PROCESSING COMPLETE ===\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Entry point\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_and_save_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91913e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
