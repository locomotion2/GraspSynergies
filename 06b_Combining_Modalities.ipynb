{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1656c2",
   "metadata": {},
   "source": [
    "### Creating 2 combined and standardized feature matrix consisting of Kinematic and EMG Data for each Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589160d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      " PRE-PROCESSING (column_then_block)\n",
      "========================================================================\n",
      "[DONE] P1: phase1 (168814, 180), phase2 (387674, 180)\n",
      "[DONE] P2: phase1 (183597, 180), phase2 (356604, 180)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'C:\\\\Users\\\\schmi\\\\Documents\\\\Studium\\\\TUM\\\\Masterthesis\\\\Experimental Data\\\\P(3)\\\\Preprocessed_Data_Matrix\\\\P3_combined_matrix_phase1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 290\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# =====================================================================\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Entry point\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# =====================================================================\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 290\u001b[0m     \u001b[43mpreprocess_and_save_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 263\u001b[0m, in \u001b[0;36mpreprocess_and_save_all_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m    261\u001b[0m out_dir \u001b[38;5;241m=\u001b[39m Path(p_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessed_Data_Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    262\u001b[0m out_dir\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 263\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_combined_matrix_phase1.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m np\u001b[38;5;241m.\u001b[39msave(out_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_combined_matrix_phase2.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, X2s)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# Remove 'combined' key before saving metadata to avoid redundancy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\schmi\\Documents\\Studium\\TUM\\Masterthesis\\Adapted Results for Paper\\GraspSynergies\\.venv\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:570\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    569\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 570\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    573\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'C:\\\\Users\\\\schmi\\\\Documents\\\\Studium\\\\TUM\\\\Masterthesis\\\\Experimental Data\\\\P(3)\\\\Preprocessed_Data_Matrix\\\\P3_combined_matrix_phase1.npy'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pre-process the multi-modal dataset into phase-specific matrices\n",
    "with block-wise Frobenius norm scaling.\n",
    "\n",
    "Rationale\n",
    "---------\n",
    "* The primary method, \"block_frobenius\", scales each modality block\n",
    "    (OTB, Myo, Kinematics) to have a unit Frobenius norm. This ensures\n",
    "    that each modality contributes equally to the MMF/NMF cost function,\n",
    "    preventing bias from modalities with more channels or higher variance.\n",
    "\n",
    "* The alternative method, \"column_then_block\", is a two-stage process\n",
    "    for fine-grained control, but block-wise scaling is recommended for\n",
    "    most synergy extraction tasks.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# =====================================================================\n",
    "# Global parameters\n",
    "# =====================================================================\n",
    "BASE_DIR: Path | str = (\n",
    "    r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\Masterthesis\\Experimental Data\"\n",
    ")\n",
    "PARTICIPANTS: list[int] = list(range(1, 9))\n",
    "PHASES: list[str] = [\"phase1\", \"phase2\"]\n",
    "N_POSE_COLUMNS: int = 6      # Pose columns at the tail of kinematics array\n",
    "DTYPE_WORK: np.dtype = np.float32\n",
    "\n",
    "# =====================================================================\n",
    "# Scaling switches\n",
    "# =====================================================================\n",
    "#  Set to \"block_frobenius\" for the recommended modality balancing.\n",
    "FEATURE_SCALE_MODE: str = \"column_then_block\"  # \"block_frobenius\" | \"column_then_block\" | \"feature\" | \"block\"\n",
    "# ‼ This flag is only used by the \"column_then_block\" mode.\n",
    "BLOCK_EQUALISE: bool = True\n",
    "\n",
    "# =====================================================================\n",
    "# Scaling helpers\n",
    "# =====================================================================\n",
    "def scale_blocks_by_frobenius(\n",
    "    X: np.ndarray,\n",
    "    idx: dict,\n",
    "    dtype: np.dtype = np.float32,\n",
    ") -> np.ndarray:\n",
    "    \"\"\" Recommended: Scales each data block to have a unit Frobenius norm.\n",
    "\n",
    "    This ensures each modality is weighted equally in the factorization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X   : array (samples × features)\n",
    "    idx : dict with keys 'otb_indices', 'myo_indices', 'kin_hand_indices';\n",
    "          each value is a (start, end) tuple of column indices.\n",
    "    dtype : working dtype.\n",
    "    \"\"\"\n",
    "    Xs = X.astype(dtype, copy=True)\n",
    "\n",
    "    # Iterate through each data block (modality)\n",
    "    for key in (\"otb_indices\", \"myo_indices\", \"kin_hand_indices\"):\n",
    "        if key not in idx or idx[key] is None:\n",
    "            continue\n",
    "        s, e = idx[key]\n",
    "        if e <= s:\n",
    "            continue\n",
    "\n",
    "        block = Xs[:, s:e]\n",
    "        frob_norm = np.linalg.norm(block, ord=\"fro\")\n",
    "\n",
    "        if frob_norm > 0:\n",
    "            Xs[:, s:e] = block / frob_norm\n",
    "\n",
    "    return Xs\n",
    "\n",
    "\n",
    "def scale_by_column_rms(\n",
    "    X: np.ndarray,\n",
    "    idx: dict,\n",
    "    block_equalise: bool = True,\n",
    "    dtype: np.dtype = np.float32,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Alternative two-stage scaling:\n",
    "\n",
    "    1) Divide *every* column by its own RMS.\n",
    "    2) If *block_equalise* is True, rescale each modality block so that\n",
    "       its Frobenius energy equals the mean energy of all present blocks.\n",
    "    \"\"\"\n",
    "    Xs = X.astype(dtype, copy=True)\n",
    "\n",
    "    # ---------- Step 1: per-feature RMS ---------------------------------\n",
    "    rms = np.linalg.norm(Xs, axis=0) / np.sqrt(len(Xs))  # column RMS\n",
    "    rms[rms == 0] = 1.0                                     # avoid div/0\n",
    "    Xs /= rms                                               # broadcasted divide\n",
    "\n",
    "    # ---------- Step 2: equalise block energies --------------------------\n",
    "    if block_equalise:\n",
    "        energies = []\n",
    "        for key in (\"otb_indices\", \"myo_indices\", \"kin_hand_indices\"):\n",
    "            if key not in idx or idx[key] is None:\n",
    "                continue\n",
    "            s, e = idx[key]\n",
    "            energies.append(np.linalg.norm(Xs[:, s:e], ord=\"fro\") ** 2)\n",
    "        if energies:                                        # at least one block\n",
    "            E_ref = float(np.mean(energies))\n",
    "            for key in (\"otb_indices\", \"myo_indices\", \"kin_hand_indices\"):\n",
    "                if key not in idx or idx[key] is None:\n",
    "                    continue\n",
    "                s, e = idx[key]\n",
    "                E_block = np.linalg.norm(Xs[:, s:e], ord=\"fro\") ** 2\n",
    "                if E_block > 0:\n",
    "                    Xs[:, s:e] *= np.sqrt(E_ref / E_block)\n",
    "\n",
    "    return Xs\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Legacy scalers (kept for reference / comparison)\n",
    "# ---------------------------------------------------------------------\n",
    "def scale_each_feature_rms(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Old: column-wise RMS only.\"\"\"\n",
    "    Xs = X.astype(DTYPE_WORK, copy=True)\n",
    "    rms = np.sqrt(np.mean(Xs ** 2, axis=0, keepdims=True))\n",
    "    rms[rms == 0] = 1.0\n",
    "    return Xs / rms\n",
    "\n",
    "\n",
    "def equalise_block_energy_sqrt_d(X: np.ndarray, idx: dict) -> np.ndarray:\n",
    "    \"\"\"Old: divide each block by √d after column scaling.\"\"\"\n",
    "    Xs = X.copy()\n",
    "    for key in (\"otb_indices\", \"myo_indices\", \"kin_hand_indices\"):\n",
    "        if key not in idx or idx[key] is None:\n",
    "            continue\n",
    "        start, end = idx[key]\n",
    "        d = end - start\n",
    "        if d > 0:\n",
    "            Xs[:, start:end] /= np.sqrt(d, dtype=DTYPE_WORK)\n",
    "    return Xs\n",
    "\n",
    "\n",
    "def scale_blocks_by_rms(X: np.ndarray, idx: dict) -> np.ndarray:\n",
    "    \"\"\"Old: one scalar per block  (Frobenius/√d).\"\"\"\n",
    "    Xs = X.astype(DTYPE_WORK, copy=True)\n",
    "    for key in (\"otb_indices\", \"myo_indices\", \"kin_hand_indices\"):\n",
    "        if key not in idx or idx[key] is None:\n",
    "            continue\n",
    "        s, e = idx[key]\n",
    "        if e <= s:\n",
    "            continue\n",
    "        block = Xs[:, s:e]\n",
    "        d = e - s\n",
    "        frob = np.linalg.norm(block, ord=\"fro\")\n",
    "        if frob > 0:\n",
    "            Xs[:, s:e] = block / (frob / np.sqrt(d, dtype=DTYPE_WORK))\n",
    "    return Xs\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# I/O helpers\n",
    "# =====================================================================\n",
    "def load_full_phase(\n",
    "    part_dir: Path | str,\n",
    "    trial: int,\n",
    "    phase: str,\n",
    "    n_pose_cols: int,\n",
    ") -> dict | None:\n",
    "    \"\"\"Read uncropped OTB, Myo and hand-only kinematics; return combined\n",
    "    matrix & column indices, or *None* if files are missing/invalid.\"\"\"\n",
    "    sync_dir = Path(part_dir, \"Synchronized Data split in Phases\")\n",
    "    kin_f = sync_dir / f\"match_{trial:02d}_{phase}_kin_norm.npy\"\n",
    "    myo_f = sync_dir / f\"match_{trial:02d}_{phase}_myo.npy\"\n",
    "    otb_f = sync_dir / f\"match_{trial:02d}_{phase}_otb.npy\"\n",
    "    if not (kin_f.exists() and myo_f.exists() and otb_f.exists()):\n",
    "        return None\n",
    "\n",
    "    kin, myo, otb = map(np.load, (kin_f, myo_f, otb_f))\n",
    "    T = min(len(kin), len(myo), len(otb))\n",
    "    if T < 5 or kin.shape[1] <= n_pose_cols:\n",
    "        return None\n",
    "\n",
    "    kin_h = kin[:T, : kin.shape[1] - n_pose_cols]  # drop pose cols\n",
    "    X = np.hstack([otb[:T], myo[:T], kin_h])\n",
    "\n",
    "    otb_end = otb.shape[1]\n",
    "    myo_end = otb_end + myo.shape[1]\n",
    "    kin_end = myo_end + kin_h.shape[1]\n",
    "\n",
    "    return {\n",
    "        \"combined\": X,\n",
    "        \"otb_indices\": (0, otb_end),\n",
    "        \"myo_indices\": (otb_end, myo_end),\n",
    "        \"kin_hand_indices\": (myo_end, kin_end),\n",
    "    }\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Main processing loop\n",
    "# =====================================================================\n",
    "def preprocess_and_save_all_data() -> None:\n",
    "    bar = \"=\" * 72\n",
    "    print(f\"\\n{bar}\\n PRE-PROCESSING ({FEATURE_SCALE_MODE})\\n{bar}\")\n",
    "\n",
    "    for pid in PARTICIPANTS:\n",
    "        p_dir = Path(BASE_DIR, f\"P({pid})\")\n",
    "        if not p_dir.is_dir():\n",
    "            print(f\"[WARN] folder missing for P{pid}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        data_phase: dict[str, list[np.ndarray]] = {ph: [] for ph in PHASES}\n",
    "        len_phase: dict[str, list[int]] = {ph: [] for ph in PHASES}\n",
    "        last_idx: dict | None = None\n",
    "\n",
    "        # --------- load all trials -----------------------------------\n",
    "        for trial in range(1, 25):\n",
    "            for ph in PHASES:\n",
    "                out = load_full_phase(p_dir, trial, ph, N_POSE_COLUMNS)\n",
    "                if out is None:\n",
    "                    continue\n",
    "                data_phase[ph].append(out[\"combined\"])\n",
    "                len_phase[ph].append(out[\"combined\"].shape[0])\n",
    "                last_idx = out                              # store mapping\n",
    "\n",
    "        if any(len(data_phase[ph]) == 0 for ph in PHASES):\n",
    "            print(f\"[WARN] P{pid}: no valid data for one phase, skipping.\")\n",
    "            continue\n",
    "        assert last_idx is not None, \"Index mapping not captured.\"\n",
    "\n",
    "        # --------- stack trials per phase ---------------------------\n",
    "        X1 = np.vstack(data_phase[\"phase1\"], dtype=DTYPE_WORK)\n",
    "        X2 = np.vstack(data_phase[\"phase2\"], dtype=DTYPE_WORK)\n",
    "\n",
    "        # --------- scaling ------------------------------------------\n",
    "        if FEATURE_SCALE_MODE == \"block_frobenius\":\n",
    "            X1s = scale_blocks_by_frobenius(X1, last_idx)\n",
    "            X2s = scale_blocks_by_frobenius(X2, last_idx)\n",
    "            \n",
    "        elif FEATURE_SCALE_MODE == \"column_then_block\":\n",
    "            X1s = scale_by_column_rms(X1, last_idx, BLOCK_EQUALISE)\n",
    "            X2s = scale_by_column_rms(X2, last_idx, BLOCK_EQUALISE)\n",
    "\n",
    "        elif FEATURE_SCALE_MODE == \"feature\":\n",
    "            X1s = scale_each_feature_rms(X1)\n",
    "            X2s = scale_each_feature_rms(X2)\n",
    "            if BLOCK_EQUALISE:                          # √d heuristic\n",
    "                X1s = equalise_block_energy_sqrt_d(X1s, last_idx)\n",
    "                X2s = equalise_block_energy_sqrt_d(X2s, last_idx)\n",
    "\n",
    "        elif FEATURE_SCALE_MODE == \"block\":\n",
    "            X1s = scale_blocks_by_rms(X1, last_idx)\n",
    "            X2s = scale_blocks_by_rms(X2, last_idx)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"FEATURE_SCALE_MODE must be 'block_frobenius', 'column_then_block', 'feature', or 'block'\"\n",
    "            )\n",
    "\n",
    "        # --------- persist ------------------------------------------\n",
    "        out_dir = Path(p_dir, \"Preprocessed_Data_Matrix\")\n",
    "        out_dir.mkdir(exist_ok=True)\n",
    "        np.save(out_dir / f\"P{pid}_combined_matrix_phase1.npy\", X1s)\n",
    "        np.save(out_dir / f\"P{pid}_combined_matrix_phase2.npy\", X2s)\n",
    "\n",
    "        # Remove 'combined' key before saving metadata to avoid redundancy\n",
    "        if 'combined' in last_idx:\n",
    "            del last_idx['combined']\n",
    "\n",
    "        meta = dict(last_idx)\n",
    "        meta[\"scaling\"] = {\n",
    "            \"feature_scale_mode\": FEATURE_SCALE_MODE,\n",
    "            \"block_equalise\": (\n",
    "                BLOCK_EQUALISE if \"column\" in FEATURE_SCALE_MODE else \"N/A\"\n",
    "            ),\n",
    "        }\n",
    "        meta[\"phase1_trial_lengths\"] = len_phase[\"phase1\"]\n",
    "        meta[\"phase2_trial_lengths\"] = len_phase[\"phase2\"]\n",
    "        joblib.dump(meta, out_dir / f\"P{pid}_feature_indices.joblib\")\n",
    "\n",
    "        print(f\"[DONE] P{pid}: phase1 {X1s.shape}, phase2 {X2s.shape}\")\n",
    "\n",
    "    print(\"=== PRE-PROCESSING COMPLETE ===\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Entry point\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_and_save_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91913e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
