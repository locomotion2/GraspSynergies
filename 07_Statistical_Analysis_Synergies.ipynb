{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Synergy Similarity between Phases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Matching Pairs with Hungarian Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cosine Similarity and Pearson Correlation between \n",
    "Reach & Grasp (Phase 1) and Lift & Hold (Phase 2)\n",
    "with Best Matching (Hungarian Algorithm) and One-Sample T-Tests\n",
    "Creates a single annotated bar plot of synergy pairs.\n",
    "\"\"\"\n",
    "    \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, ttest_1samp\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 0) Configuration\n",
    "# ------------------------------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "PARTICIPANTS = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "PHASES = [\"phase1\", \"phase2\"]\n",
    "OUTPUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q1 Synergy Similarity Between Phases\\Best Matching Hungarian\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 1) Helper Functions\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    denom = np.linalg.norm(vec_a) * np.linalg.norm(vec_b)\n",
    "    return np.dot(vec_a, vec_b) / denom if denom > 1e-12 else np.nan\n",
    "\n",
    "def load_synergy_factors(participant_dir, trial_idx, phase_name):\n",
    "    \"\"\"\n",
    "    Load synergy matrix W for a given participant, trial, and phase.\n",
    "    \"\"\"\n",
    "    synergy_dir = os.path.join(participant_dir, \"Extracted Synergies\")\n",
    "    prefix = f\"trial_{trial_idx:02d}_{phase_name}\"\n",
    "    w_file = os.path.join(synergy_dir, prefix + \"_W.npy\")\n",
    "    \n",
    "    if not os.path.exists(w_file):\n",
    "        return None\n",
    "    W = np.load(w_file)\n",
    "    return W\n",
    "\n",
    "def match_synergies_best(W1, W2):\n",
    "    \"\"\"\n",
    "    Match synergies from W1 to W2 using the Hungarian algorithm to maximize cosine similarity.\n",
    "    Returns a list of (i1, i2) index pairs.\n",
    "    \"\"\"\n",
    "    n_s1, n_s2 = W1.shape[1], W2.shape[1]\n",
    "    cost_matrix = np.zeros((n_s1, n_s2))\n",
    "    for i in range(n_s1):\n",
    "        for j in range(n_s2):\n",
    "            sim = cosine_similarity(W1[:, i], W2[:, j])\n",
    "            cost_matrix[i, j] = -sim if not np.isnan(sim) else 0\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    return list(zip(row_ind, col_ind))\n",
    "\n",
    "def sig_label(p):\n",
    "    \"\"\"\n",
    "    Return significance stars based on p-value.\n",
    "    \"\"\"\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 2) Main Analysis Function\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def synergy_similarity_analysis():\n",
    "    similarity_rows = []\n",
    "\n",
    "    for pid in PARTICIPANTS:\n",
    "        participant_str = f\"P({pid})\"\n",
    "        participant_dir = os.path.join(BASE_DIR, participant_str)\n",
    "        if not os.path.isdir(participant_dir):\n",
    "            print(f\"[WARN] Missing folder for {participant_str}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        for trial_idx in range(1, 25):\n",
    "            # Load Phase 1 & Phase 2\n",
    "            W1 = load_synergy_factors(participant_dir, trial_idx, PHASES[0])\n",
    "            W2 = load_synergy_factors(participant_dir, trial_idx, PHASES[1])\n",
    "            if W1 is None or W2 is None:\n",
    "                print(f\"[INFO] Missing synergy data for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "            if W1.shape[1] != W2.shape[1]:\n",
    "                print(f\"[WARN] Mismatch in number of synergies for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Best matching\n",
    "            pairs = match_synergies_best(W1, W2)\n",
    "            for pair_num, (i1, i2) in enumerate(pairs, start=1):\n",
    "                vec1, vec2 = W1[:, i1], W2[:, i2]\n",
    "                pear, _ = pearsonr(vec1, vec2)\n",
    "                cosi = cosine_similarity(vec1, vec2)\n",
    "                similarity_rows.append({\n",
    "                    'synergy_pair': pair_num,\n",
    "                    'pearson_corr': pear,\n",
    "                    'cosine_sim': cosi\n",
    "                })\n",
    "\n",
    "    # Create DataFrame\n",
    "    synergy_df = pd.DataFrame(similarity_rows)\n",
    "    csv_raw = os.path.join(OUTPUT_DIR, \"best_matching_synergy_raw.csv\")\n",
    "    synergy_df.to_csv(csv_raw, index=False)\n",
    "    print(f\"[INFO] Saved raw synergy data to {csv_raw}\")\n",
    "\n",
    "    # Summary Statistics\n",
    "    summary_df = synergy_df.groupby('synergy_pair').agg(\n",
    "        avg_pearson=('pearson_corr', 'mean'),\n",
    "        std_pearson=('pearson_corr', 'std'),\n",
    "        avg_cosine=('cosine_sim', 'mean'),\n",
    "        std_cosine=('cosine_sim', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Round to three decimal places\n",
    "    summary_df = summary_df.round({\n",
    "        'avg_pearson': 3,\n",
    "        'std_pearson': 3,\n",
    "        'avg_cosine': 3,\n",
    "        'std_cosine': 3\n",
    "    })\n",
    "\n",
    "    csv_summary = os.path.join(OUTPUT_DIR, \"best_matching_synergy_summary.csv\")\n",
    "    summary_df.to_csv(csv_summary, index=False)\n",
    "    print(f\"[INFO] Saved synergy summary to {csv_summary}\")\n",
    "\n",
    "    # One-Sample T-Tests\n",
    "    ttest_rows = []\n",
    "    for s_pair in summary_df['synergy_pair']:\n",
    "        sub_df = synergy_df[synergy_df['synergy_pair'] == s_pair]\n",
    "        pear_vals = sub_df['pearson_corr'].dropna()\n",
    "        cos_vals = sub_df['cosine_sim'].dropna()\n",
    "        \n",
    "        # Pearson\n",
    "        t_p, p_two = ttest_1samp(pear_vals, 0, nan_policy='omit')\n",
    "        p_pear = p_two / 2 if t_p > 0 else 1 - p_two / 2\n",
    "        \n",
    "        # Cosine\n",
    "        t_c, c_two = ttest_1samp(cos_vals, 0, nan_policy='omit')\n",
    "        p_cos = c_two / 2 if t_c > 0 else 1 - c_two / 2\n",
    "        \n",
    "        ttest_rows.append({\n",
    "            'synergy_pair': s_pair,\n",
    "            't_pear': t_p,\n",
    "            'p_pear': p_pear,\n",
    "            't_cos': t_c,\n",
    "            'p_cos': p_cos\n",
    "        })\n",
    "    \n",
    "    ttest_df = pd.DataFrame(ttest_rows)\n",
    "\n",
    "    # Round to three decimal places\n",
    "    ttest_df = ttest_df.round({\n",
    "        't_pear': 3,\n",
    "        'p_pear': 3,\n",
    "        't_cos': 3,\n",
    "        'p_cos': 3\n",
    "    })\n",
    "\n",
    "    csv_ttest = os.path.join(OUTPUT_DIR, \"best_matching_synergy_ttest.csv\")\n",
    "    ttest_df.to_csv(csv_ttest, index=False)\n",
    "    print(f\"[INFO] Saved synergy T-test results to {csv_ttest}\")\n",
    "\n",
    "    # Merge for Plotting\n",
    "    merged = summary_df.merge(ttest_df, on='synergy_pair')\n",
    "    merged['pearson_sig'] = merged['p_pear'].apply(sig_label)\n",
    "    merged['cosine_sig'] = merged['p_cos'].apply(sig_label)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(merged))\n",
    "\n",
    "    # Bars for Pearson Correlation\n",
    "    plt.bar(\n",
    "        x - bar_width/2, \n",
    "        merged['avg_pearson'], \n",
    "        bar_width, \n",
    "        yerr=merged['std_pearson'], \n",
    "        capsize=5, \n",
    "        label='Pearson Correlation', \n",
    "        color='skyblue'\n",
    "    )\n",
    "\n",
    "    # Bars for Cosine Similarity\n",
    "    plt.bar(\n",
    "        x + bar_width/2,\n",
    "        merged['avg_cosine'],\n",
    "        bar_width,\n",
    "        yerr=merged['std_cosine'],\n",
    "        capsize=5,\n",
    "        label='Cosine Similarity',\n",
    "        color='lightgreen'\n",
    "    )\n",
    "\n",
    "    # Annotate significance stars\n",
    "    for idx, row in merged.iterrows():\n",
    "        # Pearson\n",
    "        plt.text(\n",
    "            x[idx] - bar_width/2, \n",
    "            row['avg_pearson'] + row['std_pearson'] + 0.05, \n",
    "            row['pearson_sig'], \n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=14,\n",
    "            color='black'\n",
    "        )\n",
    "        # Cosine\n",
    "        plt.text(\n",
    "            x[idx] + bar_width/2, \n",
    "            row['avg_cosine'] + row['std_cosine'] + 0.05, \n",
    "            row['cosine_sig'], \n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=14,\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "    # Labels and Title\n",
    "    plt.xlabel('Synergy Pair', fontsize=12)\n",
    "    plt.ylabel('Similarity Metrics', fontsize=12)\n",
    "    plt.title('Average Pearson Correlation and Cosine Similarity per Synergy Pair\\n(Phase 1 vs Phase 2)', fontsize=16)\n",
    "    plt.xticks(x, [f\"Pair {int(s)}\" for s in merged['synergy_pair']], fontsize=12)\n",
    "    \n",
    "    # Calculate maximum y-value for ylim\n",
    "    max_p = (merged['avg_pearson'] + merged['std_pearson']).max()\n",
    "    max_c = (merged['avg_cosine'] + merged['std_cosine']).max()\n",
    "    max_value = max(max_p, max_c) + 0.2\n",
    "    plt.ylim(0, max_value)  # Start y-axis at 0\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save Plot\n",
    "    plot_path = os.path.join(OUTPUT_DIR, \"annotated_similarity_synergy_pairs.png\")\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved annotated bar plot to {plot_path}\")\n",
    "\n",
    "    # Save Summary Table as PNG\n",
    "    fig, ax = plt.subplots(figsize=(14, 2 + 0.5 * len(merged)))\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Prepare table data\n",
    "    table_df = merged.copy()\n",
    "    table_df.rename(columns={\n",
    "        'synergy_pair': 'Synergy Pair',\n",
    "        'avg_pearson': 'Avg Pearson Corr',\n",
    "        'std_pearson': 'Std Pearson Corr',\n",
    "        't_pear': 'Pearson t',\n",
    "        'p_pear': 'Pearson p (1-sided)',\n",
    "        'pearson_sig': 'Pearson Sig',\n",
    "        'avg_cosine': 'Avg Cosine Sim',\n",
    "        'std_cosine': 'Std Cosine Sim',\n",
    "        't_cos': 'Cosine t',\n",
    "        'p_cos': 'Cosine p (1-sided)',\n",
    "        'cosine_sig': 'Cosine Sig'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Select and order columns\n",
    "    table_display = ax.table(\n",
    "        cellText=table_df[['Synergy Pair', 'Avg Pearson Corr', 'Std Pearson Corr',\n",
    "                           'Pearson t', 'Pearson p (1-sided)', 'Pearson Sig',\n",
    "                           'Avg Cosine Sim', 'Std Cosine Sim',\n",
    "                           'Cosine t', 'Cosine p (1-sided)', 'Cosine Sig']].values,\n",
    "        colLabels=['Synergy Pair', 'Avg Pearson Corr', 'Std Pearson Corr',\n",
    "                   'Pearson t', 'Pearson p (1-sided)', 'Pearson Sig',\n",
    "                   'Avg Cosine Sim', 'Std Cosine Sim',\n",
    "                   'Cosine t', 'Cosine p (1-sided)', 'Cosine Sig'],\n",
    "        cellLoc='center',\n",
    "        loc='center'\n",
    "    )\n",
    "\n",
    "    # Customize table appearance\n",
    "    table_display.auto_set_font_size(False)\n",
    "    table_display.set_fontsize(10)\n",
    "    table_display.scale(1.2, 1.2)\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\"Synergy Pair Similarity: One-Sample T-tests vs Zero\", fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save Table as PNG\n",
    "    table_png = os.path.join(OUTPUT_DIR, \"summary_table_synergy_pairs.png\")\n",
    "    plt.savefig(table_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved summary table as PNG to {table_png}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 3) Execute Analysis\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    synergy_similarity_analysis()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Matching Pairs with Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Missing synergy data for Trial 20 of P(7). Skipping.\n",
      "[INFO] Missing synergy data for Trial 22 of P(7). Skipping.\n",
      "[INFO] Saved raw synergy data to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q1 Synergy Similarity Between Phases\\Best Matching Greedy\\best_matching_synergy_raw.csv\n",
      "[INFO] Saved synergy summary to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q1 Synergy Similarity Between Phases\\Best Matching Greedy\\best_matching_synergy_summary.csv\n",
      "[INFO] Saved synergy T-test (vs 0.7) results to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q1 Synergy Similarity Between Phases\\Best Matching Greedy\\best_matching_synergy_ttest.csv\n",
      "[INFO] Saved annotated bar plot to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q1 Synergy Similarity Between Phases\\Best Matching Greedy\\annotated_similarity_synergy_pairs.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_21316\\1893061735.py:359: UserWarning: Glyph 8320 (\\N{SUBSCRIPT ZERO}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_21316\\1893061735.py:359: UserWarning: Glyph 8321 (\\N{SUBSCRIPT ONE}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_21316\\1893061735.py:363: UserWarning: Glyph 8320 (\\N{SUBSCRIPT ZERO}) missing from current font.\n",
      "  plt.savefig(table_png, bbox_inches='tight', dpi=300)\n",
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_21316\\1893061735.py:363: UserWarning: Glyph 8321 (\\N{SUBSCRIPT ONE}) missing from current font.\n",
      "  plt.savefig(table_png, bbox_inches='tight', dpi=300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved summary table as PNG to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q1 Synergy Similarity Between Phases\\Best Matching Greedy\\summary_table_synergy_pairs.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cosine Similarity and Pearson Correlation between \n",
    "Reach & Grasp (Phase 1) and Lift & Hold (Phase 2)\n",
    "using Greedy Best Matching and a One-Sample T-Test vs. 0.7\n",
    "\n",
    "We keep all synergy pairs (no threshold) and test:\n",
    "H0: mean correlation <= 0.7  vs  H1: mean correlation > 0.7\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, ttest_1samp\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 0) Configuration\n",
    "# ------------------------------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "PARTICIPANTS = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "PHASES = [\"phase1\", \"phase2\"]\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q1 Synergy Similarity Between Phases\\Best Matching Greedy\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 1) Helper Functions\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    denom = np.linalg.norm(vec_a) * np.linalg.norm(vec_b)\n",
    "    return np.dot(vec_a, vec_b) / denom if denom > 1e-12 else np.nan\n",
    "\n",
    "def load_synergy_factors(participant_dir, trial_idx, phase_name):\n",
    "    \"\"\"\n",
    "    Load synergy matrix W for a given participant, trial, and phase.\n",
    "    \"\"\"\n",
    "    synergy_dir = os.path.join(participant_dir, \"Extracted Synergies\")\n",
    "    prefix = f\"trial_{trial_idx:02d}_{phase_name}\"\n",
    "    w_file = os.path.join(synergy_dir, prefix + \"_W.npy\")\n",
    "    \n",
    "    if not os.path.exists(w_file):\n",
    "        return None\n",
    "    W = np.load(w_file)\n",
    "    return W\n",
    "\n",
    "def match_synergies_greedy(W1, W2):\n",
    "    \"\"\"\n",
    "    Greedy matching of synergies to maximize cosine similarity.\n",
    "    Iteratively picks the highest similarity pair, then removes\n",
    "    those indices from further consideration.\n",
    "    Returns a list of (i1, i2) index pairs.\n",
    "    \"\"\"\n",
    "    n_s1 = W1.shape[1]\n",
    "    n_s2 = W2.shape[1]\n",
    "    \n",
    "    unmatched1 = list(range(n_s1))\n",
    "    unmatched2 = list(range(n_s2))\n",
    "    matched_pairs = []\n",
    "    \n",
    "    while unmatched1 and unmatched2:\n",
    "        best_sim = -np.inf\n",
    "        best_pair = (None, None)\n",
    "        \n",
    "        # Find highest-similarity pair among unmatched synergies\n",
    "        for i in unmatched1:\n",
    "            for j in unmatched2:\n",
    "                sim = cosine_similarity(W1[:, i], W2[:, j])\n",
    "                if not np.isnan(sim) and sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_pair = (i, j)\n",
    "        \n",
    "        # If we cannot find a valid match, break\n",
    "        if best_pair == (None, None):\n",
    "            break\n",
    "\n",
    "        # Record this match, remove from unmatched lists\n",
    "        matched_pairs.append(best_pair)\n",
    "        unmatched1.remove(best_pair[0])\n",
    "        unmatched2.remove(best_pair[1])\n",
    "    \n",
    "    return matched_pairs\n",
    "\n",
    "def sig_label(p_one_sided):\n",
    "    \"\"\"\n",
    "    Return significance stars based on a one-sided p-value.\n",
    "    \"\"\"\n",
    "    if p_one_sided < 0.001:\n",
    "        return '***'\n",
    "    elif p_one_sided < 0.01:\n",
    "        return '**'\n",
    "    elif p_one_sided < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 2) Main Analysis Function\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def synergy_similarity_analysis():\n",
    "    similarity_rows = []\n",
    "\n",
    "    for pid in PARTICIPANTS:\n",
    "        participant_str = f\"P({pid})\"\n",
    "        participant_dir = os.path.join(BASE_DIR, participant_str)\n",
    "        if not os.path.isdir(participant_dir):\n",
    "            print(f\"[WARN] Missing folder for {participant_str}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        for trial_idx in range(1, 25):\n",
    "            # Load Phase 1 & Phase 2\n",
    "            W1 = load_synergy_factors(participant_dir, trial_idx, PHASES[0])\n",
    "            W2 = load_synergy_factors(participant_dir, trial_idx, PHASES[1])\n",
    "            if W1 is None or W2 is None:\n",
    "                print(f\"[INFO] Missing synergy data for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "            if W1.shape[1] != W2.shape[1]:\n",
    "                print(f\"[WARN] Mismatch in number of synergies for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Best matching using Greedy approach\n",
    "            pairs = match_synergies_greedy(W1, W2)\n",
    "            for pair_num, (i1, i2) in enumerate(pairs, start=1):\n",
    "                vec1, vec2 = W1[:, i1], W2[:, i2]\n",
    "                \n",
    "                pear, _ = pearsonr(vec1, vec2)\n",
    "                cosi = cosine_similarity(vec1, vec2)\n",
    "                \n",
    "                # Keep all pairs\n",
    "                similarity_rows.append({\n",
    "                    'synergy_pair': pair_num,\n",
    "                    'pearson_corr': pear,\n",
    "                    'cosine_sim': cosi\n",
    "                })\n",
    "\n",
    "    # Create DataFrame of all synergy pairs\n",
    "    synergy_df = pd.DataFrame(similarity_rows)\n",
    "    csv_raw = os.path.join(OUTPUT_DIR, \"best_matching_synergy_raw.csv\")\n",
    "    synergy_df.to_csv(csv_raw, index=False)\n",
    "    print(f\"[INFO] Saved raw synergy data to {csv_raw}\")\n",
    "\n",
    "    if synergy_df.empty:\n",
    "        print(\"[INFO] No synergy data found at all. Stopping here.\")\n",
    "        return\n",
    "\n",
    "    # Summary Statistics\n",
    "    summary_df = synergy_df.groupby('synergy_pair').agg(\n",
    "        avg_pearson=('pearson_corr', 'mean'),\n",
    "        std_pearson=('pearson_corr', 'std'),\n",
    "        avg_cosine=('cosine_sim', 'mean'),\n",
    "        std_cosine=('cosine_sim', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Round to three decimal places\n",
    "    summary_df = summary_df.round({\n",
    "        'avg_pearson': 3,\n",
    "        'std_pearson': 3,\n",
    "        'avg_cosine': 3,\n",
    "        'std_cosine': 3\n",
    "    })\n",
    "\n",
    "    csv_summary = os.path.join(OUTPUT_DIR, \"best_matching_synergy_summary.csv\")\n",
    "    summary_df.to_csv(csv_summary, index=False)\n",
    "    print(f\"[INFO] Saved synergy summary to {csv_summary}\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # One-Sample T-Tests (Against 0.7, one-sided)\n",
    "    # H0: mean correlation <= 0.7\n",
    "    # H1: mean correlation > 0.7\n",
    "    # ----------------------------------------------------------------------\n",
    "    ttest_rows = []\n",
    "    for s_pair in summary_df['synergy_pair']:\n",
    "        sub_df = synergy_df[synergy_df['synergy_pair'] == s_pair]\n",
    "        pear_vals = sub_df['pearson_corr'].dropna()\n",
    "        cos_vals = sub_df['cosine_sim'].dropna()\n",
    "        \n",
    "        # T-test vs 0.7 for Pearson\n",
    "        t_p, p_two_pear = ttest_1samp(pear_vals, 0.7, nan_policy='omit')\n",
    "        # If t > 0, then mean > 0.7 -> p = p_two / 2, else p = 1 - p_two/2\n",
    "        if t_p > 0:\n",
    "            p_pear = p_two_pear / 2.0\n",
    "        else:\n",
    "            p_pear = 1.0 - (p_two_pear / 2.0)\n",
    "        \n",
    "        # T-test vs 0.7 for Cosine\n",
    "        t_c, p_two_cos = ttest_1samp(cos_vals, 0.7, nan_policy='omit')\n",
    "        # Same one-sided logic\n",
    "        if t_c > 0:\n",
    "            p_cos = p_two_cos / 2.0\n",
    "        else:\n",
    "            p_cos = 1.0 - (p_two_cos / 2.0)\n",
    "        \n",
    "        ttest_rows.append({\n",
    "            'synergy_pair': s_pair,\n",
    "            't_pear': t_p,\n",
    "            'p_pear': p_pear,\n",
    "            't_cos': t_c,\n",
    "            'p_cos': p_cos\n",
    "        })\n",
    "    \n",
    "    ttest_df = pd.DataFrame(ttest_rows)\n",
    "    # Round the T-test results\n",
    "    ttest_df = ttest_df.round({\n",
    "        't_pear': 3, 'p_pear': 3, 't_cos': 3, 'p_cos': 3\n",
    "    })\n",
    "\n",
    "    csv_ttest = os.path.join(OUTPUT_DIR, \"best_matching_synergy_ttest.csv\")\n",
    "    ttest_df.to_csv(csv_ttest, index=False)\n",
    "    print(f\"[INFO] Saved synergy T-test (vs 0.7) results to {csv_ttest}\")\n",
    "\n",
    "    # Merge results for Plotting\n",
    "    merged = summary_df.merge(ttest_df, on='synergy_pair')\n",
    "    merged['pearson_sig'] = merged['p_pear'].apply(sig_label)\n",
    "    merged['cosine_sig'] = merged['p_cos'].apply(sig_label)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    # Plotting\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(merged))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Bars for Pearson Correlation\n",
    "    plt.bar(\n",
    "        x - bar_width/2, \n",
    "        merged['avg_pearson'], \n",
    "        bar_width, \n",
    "        yerr=merged['std_pearson'], \n",
    "        capsize=5, \n",
    "        label='Pearson Correlation', \n",
    "        color='skyblue'\n",
    "    )\n",
    "\n",
    "    # Bars for Cosine Similarity\n",
    "    plt.bar(\n",
    "        x + bar_width/2,\n",
    "        merged['avg_cosine'],\n",
    "        bar_width,\n",
    "        yerr=merged['std_cosine'],\n",
    "        capsize=5,\n",
    "        label='Cosine Similarity',\n",
    "        color='lightgreen'\n",
    "    )\n",
    "\n",
    "    # Annotate significance stars\n",
    "    for idx, row in merged.iterrows():\n",
    "        # Pearson\n",
    "        plt.text(\n",
    "            x[idx] - bar_width/2, \n",
    "            row['avg_pearson'] + row['std_pearson'] + 0.02, \n",
    "            row['pearson_sig'], \n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=21,\n",
    "            color='black'\n",
    "        )\n",
    "        # Cosine\n",
    "        plt.text(\n",
    "            x[idx] + bar_width/2, \n",
    "            row['avg_cosine'] + row['std_cosine'] + 0.02, \n",
    "            row['cosine_sig'], \n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=21,\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "    # Labels and Title\n",
    "    plt.xlabel('Synergy Pairs', fontsize=21)\n",
    "    plt.ylabel('Similarity Metrics', fontsize=21)\n",
    "    plt.title(\n",
    "        'Average Pearson Correlation and Cosine Similarity\\n'\n",
    "        'Between Reach & Grasp Phase and Lift & Hold Phase',\n",
    "        fontsize=22\n",
    "    )\n",
    "    plt.xticks(x, [f\"Pair {int(s)}\" for s in merged['synergy_pair']], fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    \n",
    "    # Add annotation about H₀\n",
    "    plt.text(\n",
    "        0.01, 0.98,\n",
    "        \"One-sample t-test: H0: mean <= 0.7 vs. H1: mean > 0.7\",\n",
    "        transform=ax.transAxes,\n",
    "        ha='left',\n",
    "        va='top',\n",
    "        fontsize=15,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", alpha=0.5)\n",
    "    )\n",
    "\n",
    "    # Calculate maximum y-value for ylim\n",
    "    max_p = (merged['avg_pearson'] + merged['std_pearson']).max()\n",
    "    max_c = (merged['avg_cosine'] + merged['std_cosine']).max()\n",
    "    max_value = max(max_p, max_c) + 0.2\n",
    "    plt.ylim(0, max_value)\n",
    "\n",
    "    plt.legend(loc='upper right', fontsize=17)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save Plot\n",
    "    plot_path = os.path.join(OUTPUT_DIR, \"annotated_similarity_synergy_pairs.png\")\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved annotated bar plot to {plot_path}\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    # Save Summary Table as PNG\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    fig, ax = plt.subplots(figsize=(14, 2 + 0.5 * len(merged)))\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Prepare table data\n",
    "    table_df = merged.copy()\n",
    "    table_df.rename(columns={\n",
    "        'synergy_pair': 'Synergy Pair',\n",
    "        'avg_pearson': 'Avg Pearson Corr',\n",
    "        'std_pearson': 'Std Pearson Corr',\n",
    "        't_pear': 'Pearson t',\n",
    "        'p_pear': 'Pearson p (1-sided)',\n",
    "        'pearson_sig': 'Pearson Sig',\n",
    "        'avg_cosine': 'Avg Cosine Sim',\n",
    "        'std_cosine': 'Std Cosine Sim',\n",
    "        't_cos': 'Cosine t',\n",
    "        'p_cos': 'Cosine p (1-sided)',\n",
    "        'cosine_sig': 'Cosine Sig'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Select and order columns\n",
    "    table_display = ax.table(\n",
    "        cellText=table_df[[\n",
    "            'Synergy Pair', 'Avg Pearson Corr', 'Std Pearson Corr',\n",
    "            'Pearson t', 'Pearson p (1-sided)', 'Pearson Sig',\n",
    "            'Avg Cosine Sim', 'Std Cosine Sim',\n",
    "            'Cosine t', 'Cosine p (1-sided)', 'Cosine Sig'\n",
    "        ]].values,\n",
    "        colLabels=[\n",
    "            'Synergy Pair', 'Avg Pearson Corr', 'Std Pearson Corr',\n",
    "            'Pearson t', 'Pearson p (1-sided)', 'Pearson Sig',\n",
    "            'Avg Cosine Sim', 'Std Cosine Sim',\n",
    "            'Cosine t', 'Cosine p (1-sided)', 'Cosine Sig'\n",
    "        ],\n",
    "        cellLoc='center',\n",
    "        loc='center'\n",
    "    )\n",
    "\n",
    "    # Customize table appearance\n",
    "    table_display.auto_set_font_size(False)\n",
    "    table_display.set_fontsize(10)\n",
    "    table_display.scale(1.2, 1.2)\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\n",
    "        \"Synergy Pair Similarity (Greedy): One-Sample T-tests vs 0.7\\n\"\n",
    "        \"H₀: mean <= 0.7, H₁: mean > 0.7\",\n",
    "        fontsize=14, pad=20\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save Table as PNG\n",
    "    table_png = os.path.join(OUTPUT_DIR, \"summary_table_synergy_pairs.png\")\n",
    "    plt.savefig(table_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved summary table as PNG to {table_png}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 3) Execute Analysis\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    synergy_similarity_analysis()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Synergy Similarity between Phases by Known and Unknown Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Matching Pairs with Hungarian Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Impact of Preplanning and Task Knowledge on Extracted Synergies\n",
    "Compare \"Unknown Weight Distribution\" vs \"Known Weight Distribution\" conditions\n",
    "Applies Best Matching (Hungarian Algorithm) before calculating Pearson Correlation\n",
    "Excludes specified trials for Participants 7 and 8\n",
    "Creates annotated bar plots and summary tables with rounded numerical values.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 0) Global Configuration\n",
    "# ------------------------------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "PARTICIPANTS = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "PHASES = [\"phase1\", \"phase2\"]  # \"Reach & Grasp\" vs. \"Lift & Hold\"\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 1) Helper Functions\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def trial_info(trial_number):\n",
    "    \"\"\"\n",
    "    Returns metadata about each trial, including whether the weight distribution\n",
    "    is Known or Unknown (field 'knowledge' == 'Yes' or 'No').\n",
    "    \"\"\"\n",
    "    protocol = {\n",
    "        1:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"No\"),\n",
    "        2:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"Yes\"),\n",
    "        3:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"No\"),\n",
    "        4:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"Yes\"),\n",
    "        5:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        6:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        7:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        8:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        9:  (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"No\"),\n",
    "        10: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"Yes\"),\n",
    "        11: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        12: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        13: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        14: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        15: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        16: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        17: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        18: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        19: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        20: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        21: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        22: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        23: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"No\"),\n",
    "        24: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"Yes\"),\n",
    "    }\n",
    "    if trial_number not in protocol:\n",
    "        return None\n",
    "    tup = protocol[trial_number]\n",
    "    return {\n",
    "        'grasp_type':   tup[0],\n",
    "        'handle_type':  tup[1],\n",
    "        'weight_kg':    tup[2],\n",
    "        'lever_side':   tup[3],\n",
    "        'knowledge':    tup[4],  # 'Yes' => Known, 'No' => Unknown\n",
    "    }\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two 1D vectors.\n",
    "    Returns NaN if the denominator is too small.\n",
    "    \"\"\"\n",
    "    denom = np.linalg.norm(vec_a) * np.linalg.norm(vec_b)\n",
    "    if denom < 1e-12:\n",
    "        return np.nan\n",
    "    return np.dot(vec_a, vec_b) / denom\n",
    "\n",
    "def load_synergy_factors(participant_dir, trial_idx, phase_name):\n",
    "    \"\"\"\n",
    "    Loads the synergy factor (W) and synergy activation (H) arrays for a given\n",
    "    participant, trial, and phase from the \"Extracted Synergies\" folder.\n",
    "    \n",
    "    Returns:\n",
    "        W (numpy.ndarray): Synergy matrix (n_features, n_synergies)\n",
    "        H (numpy.ndarray): Synergy activation matrix (n_synergies, n_samples)\n",
    "        or (None, None) if files do not exist.\n",
    "    \"\"\"\n",
    "    synergy_dir = os.path.join(participant_dir, \"Extracted Synergies\")\n",
    "    prefix = f\"trial_{trial_idx:02d}_{phase_name}\"\n",
    "    w_file = os.path.join(synergy_dir, prefix + \"_W.npy\")\n",
    "    h_file = os.path.join(synergy_dir, prefix + \"_H.npy\")\n",
    "    if not (os.path.exists(w_file) and os.path.exists(h_file)):\n",
    "        return None, None\n",
    "    W = np.load(w_file)\n",
    "    H = np.load(h_file)\n",
    "    return W, H\n",
    "\n",
    "def match_synergies_best(W1, W2):\n",
    "    \"\"\"\n",
    "    Uses the Hungarian algorithm to find synergy pairs that maximize total cosine similarity.\n",
    "    Returns a list of (i1, i2) index pairs for synergies in W1 and W2.\n",
    "    \"\"\"\n",
    "    n_s1 = W1.shape[1]\n",
    "    n_s2 = W2.shape[1]\n",
    "    if n_s1 != n_s2:\n",
    "        print(\"[WARN] Number of synergies in Phase 1 and Phase 2 do not match. Skipping matching.\")\n",
    "        return []\n",
    "    cost_matrix = np.zeros((n_s1, n_s2))\n",
    "    for i in range(n_s1):\n",
    "        for j in range(n_s2):\n",
    "            sim = cosine_similarity(W1[:, i], W2[:, j])\n",
    "            cost_matrix[i, j] = -sim if not np.isnan(sim) else 0\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    return list(zip(row_ind, col_ind))\n",
    "\n",
    "def sig_label(p):\n",
    "    \"\"\"\n",
    "    Return significance stars based on p-value.\n",
    "    \"\"\"\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 2) Main Analysis Function\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def synergy_similarity_analysis_repeated():\n",
    "    \"\"\"\n",
    "    Performs a repeated-measures (within-subjects) analysis comparing synergy similarities\n",
    "    between \"Known\" and \"Unknown\" weight distribution conditions using best matching.\n",
    "    \n",
    "    Steps:\n",
    "        1. Iterates over participants and trials.\n",
    "        2. Groups trials by condition (Known vs. Unknown).\n",
    "        3. Applies best matching between Phase 1 & Phase 2 synergies.\n",
    "        4. Computes Pearson correlation between matched synergies.\n",
    "        5. Aggregates data for each participant and synergy.\n",
    "        6. Performs paired t-tests for each synergy.\n",
    "        7. Generates and saves visualizations, including annotated plots and summary tables.\n",
    "    \"\"\"\n",
    "    similarity_rows = []\n",
    "    \n",
    "    # ---- Gather synergy data from all participants & trials ----\n",
    "    for pid in PARTICIPANTS:\n",
    "        participant_str = f\"P({pid})\"\n",
    "        participant_dir = os.path.join(BASE_DIR, participant_str)\n",
    "        if not os.path.isdir(participant_dir):\n",
    "            print(f\"[WARN] Missing folder for {participant_str}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== Analyzing {participant_str} ===\")\n",
    "    \n",
    "        for trial_idx in range(1, 25):\n",
    "            \n",
    "            if pid == 7 and trial_idx in [5, 6, 7, 8]:\n",
    "                print(f\"[INFO] Skipping Participant {pid}, Trial {trial_idx} as per exclusion criteria.\")\n",
    "                continue\n",
    "\n",
    "            meta = trial_info(trial_idx)\n",
    "            if meta is None:\n",
    "                print(f\"[INFO] Trial {trial_idx} has no metadata. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            knowledge_flag = meta['knowledge']  # \"Yes\" => Known, \"No\" => Unknown\n",
    "            condition = \"Known\" if knowledge_flag == \"Yes\" else \"Unknown\"\n",
    "    \n",
    "            W_phase1, _ = load_synergy_factors(participant_dir, trial_idx, PHASES[0])\n",
    "            W_phase2, _ = load_synergy_factors(participant_dir, trial_idx, PHASES[1])\n",
    "            if W_phase1 is None or W_phase2 is None:\n",
    "                print(f\"[INFO] Missing synergy data for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "            if W_phase1.shape[1] != W_phase2.shape[1]:\n",
    "                print(f\"[WARN] Synergy count mismatch for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            # Best matching\n",
    "            matched_pairs = match_synergies_best(W_phase1, W_phase2)\n",
    "            if not matched_pairs:\n",
    "                print(f\"[WARN] No matched synergies for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            for pair_num, (i1, i2) in enumerate(matched_pairs, start=1):\n",
    "                vec1 = W_phase1[:, i1]\n",
    "                vec2 = W_phase2[:, i2]\n",
    "    \n",
    "                pear, _ = pearsonr(vec1, vec2)\n",
    "    \n",
    "                # Save row\n",
    "                similarity_rows.append({\n",
    "                    'participant': pid,\n",
    "                    'trial_idx': trial_idx,\n",
    "                    'condition': condition,      # 'Known' or 'Unknown'\n",
    "                    'synergy_idx': pair_num,     # Synergy pair number within the trial\n",
    "                    'pearson_corr': pear,\n",
    "                })\n",
    "    \n",
    "    # ---- Convert to DataFrame & Save Raw Data ----\n",
    "    synergy_df = pd.DataFrame(similarity_rows)\n",
    "    raw_csv = os.path.join(OUTPUT_DIR, \"repeated_synergy_data_raw.csv\")\n",
    "    synergy_df.to_csv(raw_csv, index=False)\n",
    "    print(f\"\\n[INFO] Saved raw synergy data to {raw_csv}\")\n",
    "    \n",
    "    # ---- Aggregation: Average per Participant, Condition, Synergy ----\n",
    "    grouped = synergy_df.groupby(['participant','condition','synergy_idx']).agg(\n",
    "        pearson_mean=('pearson_corr','mean'),\n",
    "    ).reset_index()\n",
    "    agg_csv = os.path.join(OUTPUT_DIR, \"repeated_synergy_data_agg.csv\")\n",
    "    grouped.to_csv(agg_csv, index=False)\n",
    "    print(f\"[INFO] Saved aggregated synergy data to {agg_csv}\")\n",
    "    \n",
    "    # ---- Pivot for Paired T-Tests ----\n",
    "    # For Pearson\n",
    "    pivot_pearson = grouped.pivot_table(index=['participant','synergy_idx'],\n",
    "                                        columns='condition',\n",
    "                                        values='pearson_mean').reset_index()\n",
    "    pivot_pearson.columns.name = None  \n",
    "    \n",
    "    # ---- Perform Paired T-Tests ----\n",
    "    ttest_rows = []\n",
    "    synergy_list = sorted(grouped['synergy_idx'].unique())\n",
    "    for s_idx in synergy_list:\n",
    "        pearson_subset = pivot_pearson[pivot_pearson['synergy_idx'] == s_idx]\n",
    "        known_vals_pearson = pearson_subset['Known'].dropna()\n",
    "        unknown_vals_pearson = pearson_subset['Unknown'].dropna()\n",
    "    \n",
    "        # Ensure matching participants\n",
    "        if not known_vals_pearson.index.equals(unknown_vals_pearson.index):\n",
    "            print(f\"[WARN] Participant mismatch for synergy {s_idx}. Skipping.\")\n",
    "            continue\n",
    "    \n",
    "        # Paired t-test for Pearson correlation\n",
    "        t_p, p_p = ttest_rel(known_vals_pearson, unknown_vals_pearson, nan_policy='omit')\n",
    "    \n",
    "        ttest_rows.append({\n",
    "            'synergy_idx': s_idx,\n",
    "            'pearson_t': t_p,\n",
    "            'pearson_p': p_p,\n",
    "        })\n",
    "    \n",
    "    # ---- Convert T-Test Results to DataFrame ----\n",
    "    ttest_df = pd.DataFrame(ttest_rows)\n",
    "    ttest_csv = os.path.join(OUTPUT_DIR, \"paired_ttest_synergy.csv\")\n",
    "    ttest_df.to_csv(ttest_csv, index=False)\n",
    "    print(f\"[INFO] Paired t-test results saved to {ttest_csv}\\n\")\n",
    "    \n",
    "    # ---- Print T-Test Results to Console ----\n",
    "    print(\"Paired T-Test Results for Each Synergy:\")\n",
    "    print(ttest_df.to_string(index=False))\n",
    "    \n",
    "    # ---- Significance Labeling ----\n",
    "    ttest_df['pearson_sig'] = ttest_df['pearson_p'].apply(sig_label)\n",
    "    \n",
    "    enhanced_csv = os.path.join(OUTPUT_DIR, \"paired_ttest_synergy_enhanced.csv\")\n",
    "    ttest_df.to_csv(enhanced_csv, index=False)\n",
    "    print(f\"[INFO] Enhanced t-test results with significance labels saved to {enhanced_csv}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 3) Annotated Bar Plots\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    summary_pearson = grouped.groupby(['condition','synergy_idx']).agg(\n",
    "        avg_pearson=('pearson_mean','mean'),\n",
    "        std_pearson=('pearson_mean','std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Pivot for plotting\n",
    "    pivot_plot_pearson = summary_pearson.pivot(index='synergy_idx', columns='condition', values='avg_pearson').reset_index()\n",
    "    pivot_plot_pearson_std = summary_pearson.pivot(index='synergy_idx', columns='condition', values='std_pearson').reset_index()\n",
    "    \n",
    "    # Plotting Annotated Bar Plot for Pearson Correlation\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    bar_width = 0.35\n",
    "    indices = np.arange(1, len(synergy_list)+1)  # Synergy indices\n",
    "    \n",
    "    # Bars for Known and Unknown\n",
    "    known_means_pearson = pivot_plot_pearson[pivot_plot_pearson['synergy_idx'].isin(synergy_list)]['Known']\n",
    "    known_stds_pearson = pivot_plot_pearson_std[pivot_plot_pearson_std['synergy_idx'].isin(synergy_list)]['Known']\n",
    "    unknown_means_pearson = pivot_plot_pearson[pivot_plot_pearson['synergy_idx'].isin(synergy_list)]['Unknown']\n",
    "    unknown_stds_pearson = pivot_plot_pearson_std[pivot_plot_pearson_std['synergy_idx'].isin(synergy_list)]['Unknown']\n",
    "    \n",
    "    plt.bar(indices - bar_width/2, known_means_pearson, \n",
    "            width=bar_width, yerr=known_stds_pearson,\n",
    "            capsize=5, label='Known', color='skyblue')\n",
    "    \n",
    "    plt.bar(indices + bar_width/2, unknown_means_pearson, \n",
    "            width=bar_width, yerr=unknown_stds_pearson,\n",
    "            capsize=5, label='Unknown', color='lightgreen')\n",
    "    \n",
    "    # Add significance stars based on t-tests\n",
    "    for idx, row in ttest_df.iterrows():\n",
    "        synergy = row['synergy_idx']\n",
    "        label = row['pearson_sig']\n",
    "        # Position the stars slightly above the higher bar\n",
    "        y_max = max(known_means_pearson.iloc[idx] + known_stds_pearson.iloc[idx],\n",
    "                    unknown_means_pearson.iloc[idx] + unknown_stds_pearson.iloc[idx])\n",
    "        plt.text(s=label, x=synergy, \n",
    "                 y=y_max + 0.02, \n",
    "                 ha='center', va='bottom', color='black', fontsize=14)\n",
    "    \n",
    "    plt.xlabel('Synergy Pair', fontsize=14)\n",
    "    plt.ylabel('Average Pearson Correlation', fontsize=14)\n",
    "    plt.title('Average Pearson Correlation by Condition per Synergy Pair', fontsize=16)\n",
    "    plt.xticks(indices, [f\"Synergy Pair {i}\" for i in synergy_list], fontsize=12)\n",
    "    \n",
    "    # Calculate maximum y-value for ylim\n",
    "    max_p = (known_means_pearson + known_stds_pearson).max()\n",
    "    max_u = (unknown_means_pearson + unknown_stds_pearson).max()\n",
    "    max_value = max(max_p, max_u) + 0.2\n",
    "    plt.ylim(0, max_value)  # Start y-axis at 0\n",
    "    \n",
    "    # Adjust legend position to lower right\n",
    "    plt.legend(title='Condition', loc='lower right', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    annotated_pearson_plot_path = os.path.join(OUTPUT_DIR, \"annotated_pearson_correlation_by_condition.png\")\n",
    "    plt.savefig(annotated_pearson_plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Annotated Pearson correlation by condition plot saved to: {annotated_pearson_plot_path}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 4) Boxplots\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # Boxplot for Pearson Correlation by Condition\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='condition', y='pearson_corr', data=synergy_df, palette='Blues')\n",
    "    plt.title('Pearson Correlation by Condition', fontsize=14)\n",
    "    plt.xlabel('Condition', fontsize=12)\n",
    "    plt.ylabel('Pearson Correlation', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    # Save the boxplot\n",
    "    pearson_boxplot_condition_path = os.path.join(OUTPUT_DIR, \"boxplot_pearson_by_condition.png\")\n",
    "    plt.savefig(pearson_boxplot_condition_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Boxplot of Pearson correlation saved to {pearson_boxplot_condition_path}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 5) Summary Statistics Table Adjusted as per User Request\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # ---- Create Summary Statistics ----\n",
    "    # Group by synergy index and condition to compute mean and std\n",
    "    summary_stats = grouped.groupby(['synergy_idx', 'condition']).agg(\n",
    "        Avg_Pearson_Corr=('pearson_mean', 'mean'),\n",
    "        Std_Pearson_Corr=('pearson_mean', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # ---- Pivot the Table ----\n",
    "    # Pivot to have 'Known' and 'Unknown' conditions side by side for each synergy\n",
    "    summary_pivot = summary_stats.pivot(index='synergy_idx', columns='condition', values=['Avg_Pearson_Corr', 'Std_Pearson_Corr']).reset_index()\n",
    "\n",
    "    # Flatten the MultiIndex columns\n",
    "    summary_pivot.columns = ['Synergy'] + [f\"{stat}_{cond}\" for stat, cond in summary_pivot.columns[1:]]\n",
    "\n",
    "    # ---- Merge with T-Test Results ----\n",
    "    # Select relevant columns from ttest_df\n",
    "    ttest_df_subset = ttest_df[['synergy_idx', 'pearson_t', 'pearson_p']]\n",
    "\n",
    "    # Merge with the pivoted summary statistics\n",
    "    summary_pivot = summary_pivot.merge(ttest_df_subset, left_on='Synergy', right_on='synergy_idx')\n",
    "\n",
    "    # Drop the redundant 'synergy_idx' column after merge\n",
    "    summary_pivot = summary_pivot.drop('synergy_idx', axis=1)\n",
    "\n",
    "    # ---- Round Numerical Values to Three Decimal Places ----\n",
    "    summary_pivot = summary_pivot.round({\n",
    "        'Avg_Pearson_Corr_Known': 3,\n",
    "        'Std_Pearson_Corr_Known': 3,\n",
    "        'Avg_Pearson_Corr_Unknown': 3,\n",
    "        'Std_Pearson_Corr_Unknown': 3,\n",
    "        'pearson_t': 3,\n",
    "        'pearson_p': 3,\n",
    "    })\n",
    "\n",
    "    # ---- Select and Rename Columns for Clarity ----\n",
    "    summary_pivot = summary_pivot[['Synergy',\n",
    "                                   'Avg_Pearson_Corr_Known', 'Avg_Pearson_Corr_Unknown',\n",
    "                                   'pearson_t', 'pearson_p']]\n",
    "\n",
    "    summary_pivot.rename(columns={\n",
    "        'Avg_Pearson_Corr_Known': 'Pearson Known',\n",
    "        'Avg_Pearson_Corr_Unknown': 'Pearson Unknown',\n",
    "        'pearson_t': 'Pearson t',\n",
    "        'pearson_p': 'Pearson p',\n",
    "    }, inplace=True)\n",
    "\n",
    "    # ---- Create and Save the Table as PNG ----\n",
    "    # Initialize a matplotlib figure\n",
    "    fig, ax = plt.subplots(figsize=(14, 1 + 0.5 * len(summary_pivot)))  # Adjust height based on number of synergies\n",
    "    ax.axis('off')  # Hide the axes\n",
    "\n",
    "    # Create the table\n",
    "    table = ax.table(cellText=summary_pivot.values,\n",
    "                     colLabels=summary_pivot.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "\n",
    "    # Customize table appearance\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.2)  # Adjust as needed for better fit\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Synergy Correlation Results by Condition', fontsize=16, pad=20)\n",
    "\n",
    "    # Adjust layout to ensure headers fit\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Define the path to save the table PNG\n",
    "    summary_table_png = os.path.join(OUTPUT_DIR, \"synergy_correlation_results_table.png\")\n",
    "\n",
    "    # Save the table as a PNG image\n",
    "    plt.savefig(summary_table_png, bbox_inches='tight', dpi=300)\n",
    "\n",
    "    # Close the plot to free memory\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[INFO] Synergy correlation results table saved as PNG to: {summary_table_png}\")\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 6) Annotated Summary Statistics Table with Significance\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    ttest_df_pearson = ttest_df[['synergy_idx', 'pearson_sig']].rename(columns={'pearson_sig': 'Pearson_Sig'})\n",
    "    \n",
    "    summary_stats = summary_stats.merge(ttest_df_pearson, on='synergy_idx')\n",
    "\n",
    "    # ---- Pivot again with significance ----\n",
    "    summary_pivot_sig = summary_stats.pivot(index='synergy_idx', columns='condition', values=['Avg_Pearson_Corr', 'Std_Pearson_Corr',\n",
    "                                                                                               'Pearson_Sig']).reset_index()\n",
    "    # Flatten the MultiIndex columns\n",
    "    summary_pivot_sig.columns = ['Synergy'] + [f\"{stat}_{cond}\" for stat, cond in summary_pivot_sig.columns[1:-1]] + ['Pearson_Sig']\n",
    "\n",
    "    # Sort by Synergy index\n",
    "    summary_pivot_sig.sort_values('Synergy', inplace=True)\n",
    "\n",
    "    # Create a figure for the annotated table\n",
    "    fig, ax = plt.subplots(figsize=(18, 2 + 0.6 * len(summary_pivot_sig)))  # Adjust height based on number of synergies\n",
    "    ax.axis('off')  # Hide the axes\n",
    "\n",
    "    # Prepare table data with significance annotations\n",
    "    table_data = summary_pivot_sig.values\n",
    "    column_labels = summary_pivot_sig.columns.tolist()\n",
    "\n",
    "    # Create the table\n",
    "    table = ax.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=column_labels,\n",
    "        cellLoc='center',\n",
    "        loc='center'\n",
    "    )\n",
    "\n",
    "    # Customize table appearance\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.2)\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\"Summary Statistics of Synergy Similarities by Condition with Significance\", fontsize=16, pad=20)\n",
    "\n",
    "    # Adjust layout to ensure headers fit\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the annotated table as PNG\n",
    "    summary_table_sig_png = os.path.join(OUTPUT_DIR, \"summary_statistics_synergy_with_significance.png\")\n",
    "    plt.savefig(summary_table_sig_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Summary statistics table with significance saved as PNG to: {summary_table_sig_png}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 3) Execute Analysis\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    synergy_similarity_analysis_repeated()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Matching Pairs with Greedy Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Impact of Preplanning and Task Knowledge on Extracted Synergies\n",
    "Compare \"Unknown Weight Distribution\" vs \"Known Weight Distribution\" conditions\n",
    "Applies Best Matching (Greedy Algorithm) before calculating Pearson Correlation\n",
    "Creates annotated bar plots and summary tables with rounded numerical values.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 0) Global Configuration\n",
    "# ------------------------------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "PARTICIPANTS = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "PHASES = [\"phase1\", \"phase2\"]  # \"Reach & Grasp\" vs. \"Lift & Hold\"\n",
    "\n",
    "# NEW OUTPUT DIRECTORY FOR GREEDY MATCHING\n",
    "OUTPUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 1) Helper Functions\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def trial_info(trial_number):\n",
    "    \"\"\"\n",
    "    Returns metadata about each trial, including whether the weight distribution\n",
    "    is Known or Unknown (field 'knowledge' == 'Yes' or 'No').\n",
    "    \"\"\"\n",
    "    protocol = {\n",
    "        1:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"No\"),\n",
    "        2:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"Yes\"),\n",
    "        3:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"No\"),\n",
    "        4:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"Yes\"),\n",
    "        5:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        6:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        7:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        8:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        9:  (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"No\"),\n",
    "        10: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"Yes\"),\n",
    "        11: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        12: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        13: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        14: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        15: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        16: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        17: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        18: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        19: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        20: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        21: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        22: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        23: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"No\"),\n",
    "        24: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"Yes\"),\n",
    "    }\n",
    "    if trial_number not in protocol:\n",
    "        return None\n",
    "    tup = protocol[trial_number]\n",
    "    return {\n",
    "        'grasp_type':   tup[0],\n",
    "        'handle_type':  tup[1],\n",
    "        'weight_kg':    tup[2],\n",
    "        'lever_side':   tup[3],\n",
    "        'knowledge':    tup[4],  # 'Yes' => Known, 'No' => Unknown\n",
    "    }\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two 1D vectors.\n",
    "    Returns NaN if the denominator is too small.\n",
    "    \"\"\"\n",
    "    denom = np.linalg.norm(vec_a) * np.linalg.norm(vec_b)\n",
    "    if denom < 1e-12:\n",
    "        return np.nan\n",
    "    return np.dot(vec_a, vec_b) / denom\n",
    "\n",
    "def load_synergy_factors(participant_dir, trial_idx, phase_name):\n",
    "    \"\"\"\n",
    "    Loads the synergy factor (W) and synergy activation (H) arrays for a given\n",
    "    participant, trial, and phase from the \"Extracted Synergies\" folder.\n",
    "    \n",
    "    Returns:\n",
    "        W (numpy.ndarray): Synergy matrix (n_features, n_synergies)\n",
    "        H (numpy.ndarray): Synergy activation matrix (n_synergies, n_samples)\n",
    "        or (None, None) if files do not exist.\n",
    "    \"\"\"\n",
    "    synergy_dir = os.path.join(participant_dir, \"Extracted Synergies\")\n",
    "    prefix = f\"trial_{trial_idx:02d}_{phase_name}\"\n",
    "    w_file = os.path.join(synergy_dir, prefix + \"_W.npy\")\n",
    "    h_file = os.path.join(synergy_dir, prefix + \"_H.npy\")\n",
    "    if not (os.path.exists(w_file) and os.path.exists(h_file)):\n",
    "        return None, None\n",
    "    W = np.load(w_file)\n",
    "    H = np.load(h_file)\n",
    "    return W, H\n",
    "\n",
    "def match_synergies_greedy(W1, W2):\n",
    "    \"\"\"\n",
    "    Greedy matching of synergies to maximize cosine similarity.\n",
    "    Iteratively picks the highest similarity pair, then removes\n",
    "    those indices from further consideration.\n",
    "    Returns a list of (i1, i2) index pairs.\n",
    "    \"\"\"\n",
    "    n_s1 = W1.shape[1]\n",
    "    n_s2 = W2.shape[1]\n",
    "    \n",
    "    if n_s1 != n_s2:\n",
    "        print(\"[WARN] Number of synergies in Phase 1 and Phase 2 do not match. Skipping matching.\")\n",
    "        return []\n",
    "    \n",
    "    unmatched1 = list(range(n_s1))\n",
    "    unmatched2 = list(range(n_s2))\n",
    "    matched_pairs = []\n",
    "    \n",
    "    while unmatched1 and unmatched2:\n",
    "        best_sim = -np.inf\n",
    "        best_pair = (None, None)\n",
    "        \n",
    "        # Find the highest similarity pair among the unmatched synergy columns\n",
    "        for i in unmatched1:\n",
    "            for j in unmatched2:\n",
    "                sim = cosine_similarity(W1[:, i], W2[:, j])\n",
    "                if not np.isnan(sim) and sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_pair = (i, j)\n",
    "        \n",
    "        if best_pair == (None, None):\n",
    "            # No valid match found\n",
    "            break\n",
    "        \n",
    "        # Record the best match\n",
    "        matched_pairs.append(best_pair)\n",
    "        # Remove the matched indices from further consideration\n",
    "        unmatched1.remove(best_pair[0])\n",
    "        unmatched2.remove(best_pair[1])\n",
    "    \n",
    "    return matched_pairs\n",
    "\n",
    "def sig_label(p):\n",
    "    \"\"\"\n",
    "    Return significance stars based on p-value.\n",
    "    \"\"\"\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 2) Main Analysis Function\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def synergy_similarity_analysis_repeated():\n",
    "    \"\"\"\n",
    "    Performs a repeated-measures (within-subjects) analysis comparing synergy similarities\n",
    "    between \"Known\" and \"Unknown\" weight distribution conditions using best matching (Greedy).\n",
    "    \n",
    "    Steps:\n",
    "        1. Iterates over participants and trials.\n",
    "        2. Groups trials by condition (Known vs. Unknown).\n",
    "        3. Applies best matching between Phase 1 & Phase 2 synergies (Greedy).\n",
    "        4. Computes Pearson correlation between matched synergies.\n",
    "        5. Aggregates data for each participant and synergy.\n",
    "        6. Performs paired t-tests for each synergy.\n",
    "        7. Generates and saves visualizations, including annotated plots and summary tables.\n",
    "    \"\"\"\n",
    "    similarity_rows = []\n",
    "    \n",
    "    # ---- Gather synergy data from all participants & trials ----\n",
    "    for pid in PARTICIPANTS:\n",
    "        participant_str = f\"P({pid})\"\n",
    "        participant_dir = os.path.join(BASE_DIR, participant_str)\n",
    "        if not os.path.isdir(participant_dir):\n",
    "            print(f\"[WARN] Missing folder for {participant_str}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== Analyzing {participant_str} ===\")\n",
    "    \n",
    "        for trial_idx in range(1, 25):\n",
    "            # Exclude specified trials for participant 7\n",
    "            if pid == 7 and trial_idx in [5, 6, 7, 8]:\n",
    "                print(f\"[INFO] Skipping Participant {pid}, Trial {trial_idx} as per exclusion criteria.\")\n",
    "                continue\n",
    "\n",
    "            meta = trial_info(trial_idx)\n",
    "            if meta is None:\n",
    "                print(f\"[INFO] Trial {trial_idx} has no metadata. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            knowledge_flag = meta['knowledge']  # \"Yes\" => Known, \"No\" => Unknown\n",
    "            condition = \"Known\" if knowledge_flag == \"Yes\" else \"Unknown\"\n",
    "    \n",
    "            W_phase1, _ = load_synergy_factors(participant_dir, trial_idx, PHASES[0])\n",
    "            W_phase2, _ = load_synergy_factors(participant_dir, trial_idx, PHASES[1])\n",
    "            if W_phase1 is None or W_phase2 is None:\n",
    "                print(f\"[INFO] Missing synergy data for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "            if W_phase1.shape[1] != W_phase2.shape[1]:\n",
    "                print(f\"[WARN] Synergy count mismatch for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            # Best matching (GREEDY)\n",
    "            matched_pairs = match_synergies_greedy(W_phase1, W_phase2)\n",
    "            if not matched_pairs:\n",
    "                print(f\"[WARN] No matched synergies for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            for pair_num, (i1, i2) in enumerate(matched_pairs, start=1):\n",
    "                vec1 = W_phase1[:, i1]\n",
    "                vec2 = W_phase2[:, i2]\n",
    "    \n",
    "                pear, _ = pearsonr(vec1, vec2)\n",
    "    \n",
    "                # Save row\n",
    "                similarity_rows.append({\n",
    "                    'participant': pid,\n",
    "                    'trial_idx': trial_idx,\n",
    "                    'condition': condition,      # 'Known' or 'Unknown'\n",
    "                    'synergy_idx': pair_num,     # Synergy pair number within the trial\n",
    "                    'pearson_corr': pear,\n",
    "                })\n",
    "    \n",
    "    # ---- Convert to DataFrame & Save Raw Data ----\n",
    "    synergy_df = pd.DataFrame(similarity_rows)\n",
    "    raw_csv = os.path.join(OUTPUT_DIR, \"repeated_synergy_data_raw.csv\")\n",
    "    synergy_df.to_csv(raw_csv, index=False)\n",
    "    print(f\"\\n[INFO] Saved raw synergy data to {raw_csv}\")\n",
    "    \n",
    "    if synergy_df.empty:\n",
    "        print(\"[INFO] No synergy data collected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # ---- Aggregation: Average per Participant, Condition, Synergy ----\n",
    "    grouped = synergy_df.groupby(['participant','condition','synergy_idx']).agg(\n",
    "        pearson_mean=('pearson_corr','mean'),\n",
    "    ).reset_index()\n",
    "    agg_csv = os.path.join(OUTPUT_DIR, \"repeated_synergy_data_agg.csv\")\n",
    "    grouped.to_csv(agg_csv, index=False)\n",
    "    print(f\"[INFO] Saved aggregated synergy data to {agg_csv}\")\n",
    "    \n",
    "    # ---- Pivot for Paired T-Tests ----\n",
    "    pivot_pearson = grouped.pivot_table(index=['participant','synergy_idx'],\n",
    "                                        columns='condition',\n",
    "                                        values='pearson_mean').reset_index()\n",
    "    pivot_pearson.columns.name = None  # Remove multi-level column name\n",
    "    \n",
    "    # ---- Perform Paired T-Tests ----\n",
    "    ttest_rows = []\n",
    "    synergy_list = sorted(grouped['synergy_idx'].unique())\n",
    "    for s_idx in synergy_list:\n",
    "        pearson_subset = pivot_pearson[pivot_pearson['synergy_idx'] == s_idx]\n",
    "        known_vals_pearson = pearson_subset['Known'].dropna()\n",
    "        unknown_vals_pearson = pearson_subset['Unknown'].dropna()\n",
    "    \n",
    "        # Ensure matching participants\n",
    "        if not known_vals_pearson.index.equals(unknown_vals_pearson.index):\n",
    "            print(f\"[WARN] Participant mismatch for synergy {s_idx}. Skipping.\")\n",
    "            continue\n",
    "    \n",
    "        # Paired t-test for Pearson correlation\n",
    "        t_p, p_p = ttest_rel(known_vals_pearson, unknown_vals_pearson, nan_policy='omit')\n",
    "    \n",
    "        ttest_rows.append({\n",
    "            'synergy_idx': s_idx,\n",
    "            'pearson_t': t_p,\n",
    "            'pearson_p': p_p,\n",
    "        })\n",
    "    \n",
    "    # ---- Convert T-Test Results to DataFrame ----\n",
    "    ttest_df = pd.DataFrame(ttest_rows)\n",
    "    ttest_csv = os.path.join(OUTPUT_DIR, \"paired_ttest_synergy.csv\")\n",
    "    ttest_df.to_csv(ttest_csv, index=False)\n",
    "    print(f\"[INFO] Paired t-test results saved to {ttest_csv}\\n\")\n",
    "    \n",
    "    # ---- Print T-Test Results to Console ----\n",
    "    print(\"Paired T-Test Results for Each Synergy:\")\n",
    "    print(ttest_df.to_string(index=False))\n",
    "    \n",
    "    # ---- Significance Labeling ----\n",
    "    ttest_df['pearson_sig'] = ttest_df['pearson_p'].apply(sig_label)\n",
    "    \n",
    "    enhanced_csv = os.path.join(OUTPUT_DIR, \"paired_ttest_synergy_enhanced.csv\")\n",
    "    ttest_df.to_csv(enhanced_csv, index=False)\n",
    "    print(f\"[INFO] Enhanced t-test results with significance labels saved to {enhanced_csv}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 3) Annotated Bar Plots (Pearson Correlation: Known vs. Unknown)\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # Prepare data for plotting Pearson correlations\n",
    "    summary_pearson = grouped.groupby(['condition','synergy_idx']).agg(\n",
    "        avg_pearson=('pearson_mean','mean'),\n",
    "        std_pearson=('pearson_mean','std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Pivot for plotting\n",
    "    pivot_plot_pearson = summary_pearson.pivot(index='synergy_idx', columns='condition', values='avg_pearson').reset_index()\n",
    "    pivot_plot_pearson_std = summary_pearson.pivot(index='synergy_idx', columns='condition', values='std_pearson').reset_index()\n",
    "    \n",
    "    # Plotting Annotated Bar Plot for Pearson Correlation\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    bar_width = 0.35\n",
    "    indices = np.arange(1, len(synergy_list)+1)  # Synergy indices\n",
    "    \n",
    "    # Bars for Known and Unknown\n",
    "    known_means_pearson = pivot_plot_pearson[pivot_plot_pearson['synergy_idx'].isin(synergy_list)]['Known']\n",
    "    known_stds_pearson = pivot_plot_pearson_std[pivot_plot_pearson_std['synergy_idx'].isin(synergy_list)]['Known']\n",
    "    unknown_means_pearson = pivot_plot_pearson[pivot_plot_pearson['synergy_idx'].isin(synergy_list)]['Unknown']\n",
    "    unknown_stds_pearson = pivot_plot_pearson_std[pivot_plot_pearson_std['synergy_idx'].isin(synergy_list)]['Unknown']\n",
    "    \n",
    "    plt.bar(indices - bar_width/2, known_means_pearson, \n",
    "            width=bar_width, yerr=known_stds_pearson,\n",
    "            capsize=5, label='Known', color='#F08080')\n",
    "    \n",
    "    plt.bar(indices + bar_width/2, unknown_means_pearson, \n",
    "            width=bar_width, yerr=unknown_stds_pearson,\n",
    "            capsize=5, label='Unknown', color='#F0E68C')\n",
    "    \n",
    "    for idx, row in ttest_df.iterrows():\n",
    "        synergy = row['synergy_idx']\n",
    "        label = row['pearson_sig']\n",
    "        # Convert synergy_idx to the index in synergy_list\n",
    "        synergy_position = synergy_list.index(synergy)  \n",
    "        km = known_means_pearson.iloc[synergy_position]\n",
    "        ks = known_stds_pearson.iloc[synergy_position]\n",
    "        um = unknown_means_pearson.iloc[synergy_position]\n",
    "        us = unknown_stds_pearson.iloc[synergy_position]\n",
    "        y_max = max(km + ks, um + us)\n",
    "        \n",
    "        plt.text(s=label, \n",
    "                 x=indices[synergy_position], \n",
    "                 y=y_max + 0.02, \n",
    "                 ha='center', va='bottom', color='black', fontsize=21)  # 1.5× original\n",
    "    \n",
    "    plt.xlabel('Synergy Pairs', fontsize=21)   # 1.5× original\n",
    "    plt.ylabel('Average Pearson Correlation', fontsize=21)  # 1.5× original\n",
    "    plt.title('Average Pearson Correlation between Synergy Pairs for Known & Unknown', fontsize=22)  # 1.5× original\n",
    "    plt.xticks(indices, [f\"{s}\" for s in synergy_list], fontsize=16)  # 1.5× original\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "    # Calculate maximum y-value for ylim\n",
    "    max_p = (known_means_pearson + known_stds_pearson).max()\n",
    "    max_u = (unknown_means_pearson + unknown_stds_pearson).max()\n",
    "    max_value = max(max_p, max_u) + 0.2\n",
    "    plt.ylim(0, max_value)  # Start y-axis at 0\n",
    "    \n",
    "    # Adjust legend position\n",
    "    plt.legend(title='Condition', loc='upper right', fontsize=17)  # 1.5× original\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    annotated_pearson_plot_path = os.path.join(OUTPUT_DIR, \"annotated_pearson_correlation_by_condition.png\")\n",
    "    plt.savefig(annotated_pearson_plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Annotated Pearson correlation by condition plot saved to: {annotated_pearson_plot_path}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 4) Boxplots\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # Boxplot for Pearson Correlation by Condition\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='condition', y='pearson_corr', data=synergy_df, palette='Blues')\n",
    "    plt.title('Pearson Correlation by Condition', fontsize=21)  # 1.5× original\n",
    "    plt.xlabel('Condition', fontsize=18)  # 1.5× original\n",
    "    plt.ylabel('Pearson Correlation', fontsize=18)  # 1.5× original\n",
    "    plt.tight_layout()\n",
    "    # Save the boxplot\n",
    "    pearson_boxplot_condition_path = os.path.join(OUTPUT_DIR, \"boxplot_pearson_by_condition.png\")\n",
    "    plt.savefig(pearson_boxplot_condition_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Boxplot of Pearson correlation saved to {pearson_boxplot_condition_path}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 5) Summary Statistics Table Adjusted\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # Group by synergy index and condition to compute mean and std\n",
    "    summary_stats = grouped.groupby(['synergy_idx', 'condition']).agg(\n",
    "        Avg_Pearson_Corr=('pearson_mean', 'mean'),\n",
    "        Std_Pearson_Corr=('pearson_mean', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Pivot to have 'Known' and 'Unknown' side by side\n",
    "    summary_pivot = summary_stats.pivot(\n",
    "        index='synergy_idx', \n",
    "        columns='condition', \n",
    "        values=['Avg_Pearson_Corr', 'Std_Pearson_Corr']\n",
    "    ).reset_index()\n",
    "\n",
    "    # Flatten the MultiIndex columns\n",
    "    summary_pivot.columns = ['Synergy'] + [\n",
    "        f\"{stat}_{cond}\" for stat, cond in summary_pivot.columns[1:]\n",
    "    ]\n",
    "\n",
    "    # Merge with T-Test Results\n",
    "    ttest_df_subset = ttest_df[['synergy_idx', 'pearson_t', 'pearson_p']]\n",
    "    summary_pivot = summary_pivot.merge(ttest_df_subset, left_on='Synergy', right_on='synergy_idx')\n",
    "    summary_pivot = summary_pivot.drop('synergy_idx', axis=1)\n",
    "\n",
    "    # Round\n",
    "    summary_pivot = summary_pivot.round({\n",
    "        'Avg_Pearson_Corr_Known': 3,\n",
    "        'Std_Pearson_Corr_Known': 3,\n",
    "        'Avg_Pearson_Corr_Unknown': 3,\n",
    "        'Std_Pearson_Corr_Unknown': 3,\n",
    "        'pearson_t': 3,\n",
    "        'pearson_p': 3,\n",
    "    })\n",
    "\n",
    "    # Select and rename columns\n",
    "    summary_pivot = summary_pivot[[\n",
    "        'Synergy',\n",
    "        'Avg_Pearson_Corr_Known', 'Avg_Pearson_Corr_Unknown',\n",
    "        'pearson_t', 'pearson_p'\n",
    "    ]]\n",
    "    summary_pivot.rename(columns={\n",
    "        'Avg_Pearson_Corr_Known': 'Pearson Known',\n",
    "        'Avg_Pearson_Corr_Unknown': 'Pearson Unknown',\n",
    "        'pearson_t': 'Pearson t',\n",
    "        'pearson_p': 'Pearson p',\n",
    "    }, inplace=True)\n",
    "\n",
    "    # ---- Create and Save the Table as PNG ----\n",
    "    fig, ax = plt.subplots(figsize=(14, 1 + 0.5 * len(summary_pivot)))\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(cellText=summary_pivot.values,\n",
    "                     colLabels=summary_pivot.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(18)  # 1.5× original\n",
    "    table.scale(1.2, 1.2)\n",
    "\n",
    "    plt.title('Synergy Correlation Results by Condition (Greedy Matching)', fontsize=24, pad=30)  # 1.5× original\n",
    "    plt.tight_layout()\n",
    "\n",
    "    summary_table_png = os.path.join(OUTPUT_DIR, \"synergy_correlation_results_table.png\")\n",
    "    plt.savefig(summary_table_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[INFO] Synergy correlation results table saved as PNG to: {summary_table_png}\")\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 6) Annotated Summary Statistics Table with Significance\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # Merge significance labels\n",
    "    ttest_df_pearson = ttest_df[['synergy_idx', 'pearson_sig']].rename(columns={'pearson_sig': 'Pearson_Sig'})\n",
    "    summary_stats = summary_stats.merge(ttest_df_pearson, on='synergy_idx', how='left')\n",
    "\n",
    "    # Pivot again with significance\n",
    "    summary_pivot_sig = summary_stats.pivot(\n",
    "        index='synergy_idx', \n",
    "        columns='condition', \n",
    "        values=['Avg_Pearson_Corr', 'Std_Pearson_Corr', 'Pearson_Sig']\n",
    "    ).reset_index()\n",
    "\n",
    "    # Flatten columns\n",
    "    col_names = summary_pivot_sig.columns\n",
    "    new_cols = []\n",
    "    for c1, c2 in col_names:\n",
    "        if c1 == 'synergy_idx':\n",
    "            new_cols.append(\"Synergy\")\n",
    "        else:\n",
    "            new_cols.append(f\"{c1}_{c2}\")\n",
    "    summary_pivot_sig.columns = new_cols\n",
    "\n",
    "    # Sort by synergy\n",
    "    summary_pivot_sig.sort_values('Synergy', inplace=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18, 2 + 0.6 * len(summary_pivot_sig)))\n",
    "    ax.axis('off')\n",
    "\n",
    "    table_data = summary_pivot_sig.values\n",
    "    column_labels = summary_pivot_sig.columns.tolist()\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=column_labels,\n",
    "        cellLoc='center',\n",
    "        loc='center'\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(18)  # 1.5× original\n",
    "    table.scale(1.2, 1.2)\n",
    "\n",
    "    plt.title(\"Summary Statistics of Synergy Similarities by Condition (Greedy) with Significance\", \n",
    "              fontsize=24, pad=30)  # 1.5× original\n",
    "    plt.tight_layout()\n",
    "\n",
    "    summary_table_sig_png = os.path.join(OUTPUT_DIR, \"summary_statistics_synergy_with_significance.png\")\n",
    "    plt.savefig(summary_table_sig_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Summary statistics table with significance saved as PNG to {summary_table_sig_png}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 3) Execute Analysis\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    synergy_similarity_analysis_repeated()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Correlation around Lift - Onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analyzing P(1) ===\n",
      "\n",
      "=== Analyzing P(2) ===\n",
      "\n",
      "=== Analyzing P(3) ===\n",
      "\n",
      "=== Analyzing P(4) ===\n",
      "\n",
      "=== Analyzing P(5) ===\n",
      "\n",
      "=== Analyzing P(6) ===\n",
      "\n",
      "=== Analyzing P(7) ===\n",
      "[INFO] Skipping Participant 7, Trial 5.\n",
      "[INFO] Skipping Participant 7, Trial 6.\n",
      "[INFO] Skipping Participant 7, Trial 7.\n",
      "[INFO] Skipping Participant 7, Trial 8.\n",
      "[INFO] Missing synergy data for Trial 20 of P(7). Skipping.\n",
      "[INFO] Missing synergy data for Trial 22 of P(7). Skipping.\n",
      "\n",
      "=== Analyzing P(8) ===\n",
      "\n",
      "[INFO] Saved raw synergy data to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\repeated_synergy_data_raw_liftonset.csv\n",
      "[INFO] Saved aggregated synergy data to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\repeated_synergy_data_agg_liftonset.csv\n",
      "[INFO] Paired t-test results saved to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\paired_ttest_synergy_liftonset.csv\n",
      "\n",
      "Paired T-Test Results for Each Synergy:\n",
      " synergy_idx  pearson_t  pearson_p\n",
      "           1  -1.018133   0.342507\n",
      "           2  -0.435982   0.675979\n",
      "           3   1.287997   0.238687\n",
      "           4   0.672115   0.523068\n",
      "           5   1.709216   0.131159\n",
      "[INFO] Enhanced t-test results saved to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\paired_ttest_synergy_enhanced_liftonset.csv\n",
      "[INFO] Annotated Pearson correlation by condition plot saved to: C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\annotated_pearson_correlation_by_condition_liftonset.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_21316\\3567953577.py:298: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='condition', y='pearson_corr', data=synergy_df, palette='Blues')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Boxplot of Pearson correlation saved to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\boxplot_pearson_by_condition_liftonset.png\n",
      "[INFO] Synergy correlation results table saved as PNG to: C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\synergy_correlation_results_table_liftonset.png\n",
      "[INFO] Summary statistics table with significance saved as PNG to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\\summary_statistics_synergy_with_significance_liftonset.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 0) Global Configuration\n",
    "# ------------------------------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "PARTICIPANTS = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "PHASES = [\"phase1\", \"phase2\"]\n",
    "\n",
    "# NEW OUTPUT DIRECTORY FOR GREEDY MATCHING WITH LIFTONSET SYNERGIES\n",
    "OUTPUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q2 Synergy Similarity By Knowledge Condition\\Best Matching Greedy\\LiftOnset\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 1) Helper Functions\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def trial_info(trial_number):\n",
    "    protocol = {\n",
    "        1:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"No\"),\n",
    "        2:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"Yes\"),\n",
    "        3:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"No\"),\n",
    "        4:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"Yes\"),\n",
    "        5:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        6:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        7:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        8:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        9:  (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"No\"),\n",
    "        10: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"Yes\"),\n",
    "        11: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        12: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        13: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        14: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        15: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        16: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        17: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        18: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        19: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        20: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        21: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        22: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        23: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"No\"),\n",
    "        24: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"Yes\"),\n",
    "    }\n",
    "    if trial_number not in protocol:\n",
    "        return None\n",
    "    tup = protocol[trial_number]\n",
    "    return {\n",
    "        'grasp_type':   tup[0],\n",
    "        'handle_type':  tup[1],\n",
    "        'weight_kg':    tup[2],\n",
    "        'lever_side':   tup[3],\n",
    "        'knowledge':    tup[4],\n",
    "    }\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    denom = np.linalg.norm(vec_a) * np.linalg.norm(vec_b)\n",
    "    if denom < 1e-12:\n",
    "        return np.nan\n",
    "    return np.dot(vec_a, vec_b) / denom\n",
    "\n",
    "def load_synergy_factors(participant_dir, trial_idx, phase_name):\n",
    "    \"\"\"\n",
    "    Modified to load synergy factors at lift onset.\n",
    "    \"\"\"\n",
    "    # Point to the directory containing synergies at lift onset\n",
    "    synergy_dir = os.path.join(participant_dir, \"Synergies at Lift-Onset\")\n",
    "    # Adjust prefix to include '_liftonset' suffix as per file naming pattern\n",
    "    prefix = f\"trial_{trial_idx:02d}_{phase_name}_liftonset\"\n",
    "    w_file = os.path.join(synergy_dir, prefix + \"_W.npy\")\n",
    "    h_file = os.path.join(synergy_dir, prefix + \"_H.npy\")\n",
    "    if not (os.path.exists(w_file) and os.path.exists(h_file)):\n",
    "        return None, None\n",
    "    W = np.load(w_file)\n",
    "    H = np.load(h_file)\n",
    "    return W, H\n",
    "\n",
    "def match_synergies_greedy(W1, W2):\n",
    "    n_s1 = W1.shape[1]\n",
    "    n_s2 = W2.shape[1]\n",
    "    \n",
    "    if n_s1 != n_s2:\n",
    "        print(\"[WARN] Number of synergies do not match. Skipping matching.\")\n",
    "        return []\n",
    "    \n",
    "    unmatched1 = list(range(n_s1))\n",
    "    unmatched2 = list(range(n_s2))\n",
    "    matched_pairs = []\n",
    "    \n",
    "    while unmatched1 and unmatched2:\n",
    "        best_sim = -np.inf\n",
    "        best_pair = (None, None)\n",
    "        for i in unmatched1:\n",
    "            for j in unmatched2:\n",
    "                sim = cosine_similarity(W1[:, i], W2[:, j])\n",
    "                if not np.isnan(sim) and sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_pair = (i, j)\n",
    "        if best_pair == (None, None):\n",
    "            break\n",
    "        matched_pairs.append(best_pair)\n",
    "        unmatched1.remove(best_pair[0])\n",
    "        unmatched2.remove(best_pair[1])\n",
    "    \n",
    "    return matched_pairs\n",
    "\n",
    "def sig_label(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 2) Main Analysis Function\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def synergy_similarity_analysis_repeated():\n",
    "    similarity_rows = []\n",
    "    \n",
    "    for pid in PARTICIPANTS:\n",
    "        participant_str = f\"P({pid})\"\n",
    "        participant_dir = os.path.join(BASE_DIR, participant_str)\n",
    "        if not os.path.isdir(participant_dir):\n",
    "            print(f\"[WARN] Missing folder for {participant_str}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== Analyzing {participant_str} ===\")\n",
    "    \n",
    "        for trial_idx in range(1, 25):\n",
    "            if pid == 7 and trial_idx in [5, 6, 7, 8]:\n",
    "                print(f\"[INFO] Skipping Participant {pid}, Trial {trial_idx}.\")\n",
    "                continue\n",
    "\n",
    "            meta = trial_info(trial_idx)\n",
    "            if meta is None:\n",
    "                print(f\"[INFO] Trial {trial_idx} has no metadata. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            knowledge_flag = meta['knowledge']\n",
    "            condition = \"Known\" if knowledge_flag == \"Yes\" else \"Unknown\"\n",
    "    \n",
    "            W_phase1, _ = load_synergy_factors(participant_dir, trial_idx, PHASES[0])\n",
    "            W_phase2, _ = load_synergy_factors(participant_dir, trial_idx, PHASES[1])\n",
    "            if W_phase1 is None or W_phase2 is None:\n",
    "                print(f\"[INFO] Missing synergy data for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "            if W_phase1.shape[1] != W_phase2.shape[1]:\n",
    "                print(f\"[WARN] Synergy count mismatch for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            matched_pairs = match_synergies_greedy(W_phase1, W_phase2)\n",
    "            if not matched_pairs:\n",
    "                print(f\"[WARN] No matched synergies for Trial {trial_idx} of {participant_str}. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            for pair_num, (i1, i2) in enumerate(matched_pairs, start=1):\n",
    "                vec1 = W_phase1[:, i1]\n",
    "                vec2 = W_phase2[:, i2]\n",
    "    \n",
    "                pear, _ = pearsonr(vec1, vec2)\n",
    "    \n",
    "                similarity_rows.append({\n",
    "                    'participant': pid,\n",
    "                    'trial_idx': trial_idx,\n",
    "                    'condition': condition,\n",
    "                    'synergy_idx': pair_num,\n",
    "                    'pearson_corr': pear,\n",
    "                })\n",
    "    \n",
    "    synergy_df = pd.DataFrame(similarity_rows)\n",
    "    raw_csv = os.path.join(OUTPUT_DIR, \"repeated_synergy_data_raw_liftonset.csv\")\n",
    "    synergy_df.to_csv(raw_csv, index=False)\n",
    "    print(f\"\\n[INFO] Saved raw synergy data to {raw_csv}\")\n",
    "    \n",
    "    if synergy_df.empty:\n",
    "        print(\"[INFO] No synergy data collected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    grouped = synergy_df.groupby(['participant','condition','synergy_idx']).agg(\n",
    "        pearson_mean=('pearson_corr','mean'),\n",
    "    ).reset_index()\n",
    "    agg_csv = os.path.join(OUTPUT_DIR, \"repeated_synergy_data_agg_liftonset.csv\")\n",
    "    grouped.to_csv(agg_csv, index=False)\n",
    "    print(f\"[INFO] Saved aggregated synergy data to {agg_csv}\")\n",
    "    \n",
    "    pivot_pearson = grouped.pivot_table(index=['participant','synergy_idx'],\n",
    "                                        columns='condition',\n",
    "                                        values='pearson_mean').reset_index()\n",
    "    pivot_pearson.columns.name = None\n",
    "    \n",
    "    ttest_rows = []\n",
    "    synergy_list = sorted(grouped['synergy_idx'].unique())\n",
    "    for s_idx in synergy_list:\n",
    "        pearson_subset = pivot_pearson[pivot_pearson['synergy_idx'] == s_idx]\n",
    "        known_vals_pearson = pearson_subset['Known'].dropna()\n",
    "        unknown_vals_pearson = pearson_subset['Unknown'].dropna()\n",
    "    \n",
    "        if not known_vals_pearson.index.equals(unknown_vals_pearson.index):\n",
    "            print(f\"[WARN] Participant mismatch for synergy {s_idx}. Skipping.\")\n",
    "            continue\n",
    "    \n",
    "        t_p, p_p = ttest_rel(known_vals_pearson, unknown_vals_pearson, nan_policy='omit')\n",
    "    \n",
    "        ttest_rows.append({\n",
    "            'synergy_idx': s_idx,\n",
    "            'pearson_t': t_p,\n",
    "            'pearson_p': p_p,\n",
    "        })\n",
    "    \n",
    "    ttest_df = pd.DataFrame(ttest_rows)\n",
    "    ttest_csv = os.path.join(OUTPUT_DIR, \"paired_ttest_synergy_liftonset.csv\")\n",
    "    ttest_df.to_csv(ttest_csv, index=False)\n",
    "    print(f\"[INFO] Paired t-test results saved to {ttest_csv}\\n\")\n",
    "    \n",
    "    print(\"Paired T-Test Results for Each Synergy:\")\n",
    "    print(ttest_df.to_string(index=False))\n",
    "    \n",
    "    ttest_df['pearson_sig'] = ttest_df['pearson_p'].apply(sig_label)\n",
    "    \n",
    "    enhanced_csv = os.path.join(OUTPUT_DIR, \"paired_ttest_synergy_enhanced_liftonset.csv\")\n",
    "    ttest_df.to_csv(enhanced_csv, index=False)\n",
    "    print(f\"[INFO] Enhanced t-test results saved to {enhanced_csv}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 3) Annotated Bar Plots (Pearson Correlation: Known vs. Unknown) using Lift-Onset Synergies\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    summary_pearson = grouped.groupby(['condition','synergy_idx']).agg(\n",
    "        avg_pearson=('pearson_mean','mean'),\n",
    "        std_pearson=('pearson_mean','std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    pivot_plot_pearson = summary_pearson.pivot(index='synergy_idx', columns='condition', values='avg_pearson').reset_index()\n",
    "    pivot_plot_pearson_std = summary_pearson.pivot(index='synergy_idx', columns='condition', values='std_pearson').reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    bar_width = 0.35\n",
    "    indices = np.arange(1, len(synergy_list)+1)\n",
    "    \n",
    "    known_means_pearson = pivot_plot_pearson[pivot_plot_pearson['synergy_idx'].isin(synergy_list)]['Known']\n",
    "    known_stds_pearson = pivot_plot_pearson_std[pivot_plot_pearson_std['synergy_idx'].isin(synergy_list)]['Known']\n",
    "    unknown_means_pearson = pivot_plot_pearson[pivot_plot_pearson['synergy_idx'].isin(synergy_list)]['Unknown']\n",
    "    unknown_stds_pearson = pivot_plot_pearson_std[pivot_plot_pearson_std['synergy_idx'].isin(synergy_list)]['Unknown']\n",
    "    \n",
    "    plt.bar(indices - bar_width/2, known_means_pearson, \n",
    "            width=bar_width, yerr=known_stds_pearson,\n",
    "            capsize=5, label='Known', color='#F08080')\n",
    "    \n",
    "    plt.bar(indices + bar_width/2, unknown_means_pearson, \n",
    "            width=bar_width, yerr=unknown_stds_pearson,\n",
    "            capsize=5, label='Unknown', color='#F0E68C')\n",
    "    \n",
    "    for idx, row in ttest_df.iterrows():\n",
    "        synergy = row['synergy_idx']\n",
    "        label = row['pearson_sig']\n",
    "        synergy_position = synergy_list.index(synergy)\n",
    "        km = known_means_pearson.iloc[synergy_position]\n",
    "        ks = known_stds_pearson.iloc[synergy_position]\n",
    "        um = unknown_means_pearson.iloc[synergy_position]\n",
    "        us = unknown_stds_pearson.iloc[synergy_position]\n",
    "        y_max = max(km + ks, um + us)\n",
    "        \n",
    "        plt.text(s=label, \n",
    "                 x=indices[synergy_position], \n",
    "                 y=y_max + 0.02, \n",
    "                 ha='center', va='bottom', color='black', fontsize=21)\n",
    "    \n",
    "    plt.xlabel('Synergy Pairs', fontsize=21)\n",
    "    plt.ylabel('Average Pearson Correlation', fontsize=21)\n",
    "    plt.title('Average Pearson Correlation between Synergy Pairs for Known & Unknown (Lift-Onset)', fontsize=22)\n",
    "    plt.xticks(indices, [f\"{s}\" for s in synergy_list], fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    \n",
    "    max_p = (known_means_pearson + known_stds_pearson).max()\n",
    "    max_u = (unknown_means_pearson + unknown_stds_pearson).max()\n",
    "    max_value = max(max_p, max_u) + 0.2\n",
    "    plt.ylim(0, max_value)\n",
    "    \n",
    "    plt.legend(title='Condition', loc='upper right', fontsize=17)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    annotated_pearson_plot_path = os.path.join(OUTPUT_DIR, \"annotated_pearson_correlation_by_condition_liftonset.png\")\n",
    "    plt.savefig(annotated_pearson_plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Annotated Pearson correlation by condition plot saved to: {annotated_pearson_plot_path}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 4) Boxplots\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='condition', y='pearson_corr', data=synergy_df, palette='Blues')\n",
    "    plt.title('Pearson Correlation by Condition (Lift-Onset)', fontsize=21)\n",
    "    plt.xlabel('Condition', fontsize=18)\n",
    "    plt.ylabel('Pearson Correlation', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    pearson_boxplot_condition_path = os.path.join(OUTPUT_DIR, \"boxplot_pearson_by_condition_liftonset.png\")\n",
    "    plt.savefig(pearson_boxplot_condition_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Boxplot of Pearson correlation saved to {pearson_boxplot_condition_path}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 5) Summary Statistics Table Adjusted\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    summary_stats = grouped.groupby(['synergy_idx', 'condition']).agg(\n",
    "        Avg_Pearson_Corr=('pearson_mean', 'mean'),\n",
    "        Std_Pearson_Corr=('pearson_mean', 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    summary_pivot = summary_stats.pivot(\n",
    "        index='synergy_idx', \n",
    "        columns='condition', \n",
    "        values=['Avg_Pearson_Corr', 'Std_Pearson_Corr']\n",
    "    ).reset_index()\n",
    "    \n",
    "    summary_pivot.columns = ['Synergy'] + [\n",
    "        f\"{stat}_{cond}\" for stat, cond in summary_pivot.columns[1:]\n",
    "    ]\n",
    "    \n",
    "    ttest_df_subset = ttest_df[['synergy_idx', 'pearson_t', 'pearson_p']]\n",
    "    summary_pivot = summary_pivot.merge(ttest_df_subset, left_on='Synergy', right_on='synergy_idx')\n",
    "    summary_pivot = summary_pivot.drop('synergy_idx', axis=1)\n",
    "    \n",
    "    summary_pivot = summary_pivot.round({\n",
    "        'Avg_Pearson_Corr_Known': 3,\n",
    "        'Std_Pearson_Corr_Known': 3,\n",
    "        'Avg_Pearson_Corr_Unknown': 3,\n",
    "        'Std_Pearson_Corr_Unknown': 3,\n",
    "        'pearson_t': 3,\n",
    "        'pearson_p': 3,\n",
    "    })\n",
    "    \n",
    "    summary_pivot = summary_pivot[[\n",
    "        'Synergy',\n",
    "        'Avg_Pearson_Corr_Known', 'Avg_Pearson_Corr_Unknown',\n",
    "        'pearson_t', 'pearson_p'\n",
    "    ]]\n",
    "    summary_pivot.rename(columns={\n",
    "        'Avg_Pearson_Corr_Known': 'Pearson Known',\n",
    "        'Avg_Pearson_Corr_Unknown': 'Pearson Unknown',\n",
    "        'pearson_t': 'Pearson t',\n",
    "        'pearson_p': 'Pearson p',\n",
    "    }, inplace=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 1 + 0.5 * len(summary_pivot)))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table = ax.table(cellText=summary_pivot.values,\n",
    "                     colLabels=summary_pivot.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(18)\n",
    "    table.scale(1.2, 1.2)\n",
    "    \n",
    "    plt.title('Synergy Correlation Results by Condition (Greedy Matching, Lift-Onset)', fontsize=24, pad=30)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    summary_table_png = os.path.join(OUTPUT_DIR, \"synergy_correlation_results_table_liftonset.png\")\n",
    "    plt.savefig(summary_table_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[INFO] Synergy correlation results table saved as PNG to: {summary_table_png}\")\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # 6) Annotated Summary Statistics Table with Significance\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    ttest_df_pearson = ttest_df[['synergy_idx', 'pearson_sig']].rename(columns={'pearson_sig': 'Pearson_Sig'})\n",
    "    summary_stats = summary_stats.merge(ttest_df_pearson, on='synergy_idx', how='left')\n",
    "    \n",
    "    summary_pivot_sig = summary_stats.pivot(\n",
    "        index='synergy_idx', \n",
    "        columns='condition', \n",
    "        values=['Avg_Pearson_Corr', 'Std_Pearson_Corr', 'Pearson_Sig']\n",
    "    ).reset_index()\n",
    "    \n",
    "    col_names = summary_pivot_sig.columns\n",
    "    new_cols = []\n",
    "    for c1, c2 in col_names:\n",
    "        if c1 == 'synergy_idx':\n",
    "            new_cols.append(\"Synergy\")\n",
    "        else:\n",
    "            new_cols.append(f\"{c1}_{c2}\")\n",
    "    summary_pivot_sig.columns = new_cols\n",
    "    \n",
    "    summary_pivot_sig.sort_values('Synergy', inplace=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 2 + 0.6 * len(summary_pivot_sig)))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table_data = summary_pivot_sig.values\n",
    "    column_labels = summary_pivot_sig.columns.tolist()\n",
    "    \n",
    "    table = ax.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=column_labels,\n",
    "        cellLoc='center',\n",
    "        loc='center'\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(18)\n",
    "    table.scale(1.2, 1.2)\n",
    "    \n",
    "    plt.title(\"Summary Statistics of Synergy Similarities by Condition (Greedy, Lift-Onset)\", \n",
    "              fontsize=24, pad=30)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    summary_table_sig_png = os.path.join(OUTPUT_DIR, \"summary_statistics_synergy_with_significance_liftonset.png\")\n",
    "    plt.savefig(summary_table_sig_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Summary statistics table with significance saved as PNG to {summary_table_sig_png}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 3) Execute Analysis\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    synergy_similarity_analysis_repeated()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Anticipatory Information during Lift Onset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Across Synergies computed around the lift onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved raw correlation comparison to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q3 Anticipatory Information at Lift Onset\\mean_correlation_full_vs_liftonset.csv\n",
      "=== Paired T-Test: Full Phase vs. Lift-Onset Phase ===\n",
      "T-statistic = -13.952, p-value = 0.000000 => ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_15564\\1123876947.py:213: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='phase_window', y='corr', data=df_melt, palette=\"Set2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved boxplot comparing Full vs. Lift-Onset to C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q3 Anticipatory Information at Lift Onset\\boxplot_full_vs_liftonset.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 0) Global Configuration\n",
    "# ------------------------------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "PARTICIPANTS = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "PHASES = [\"phase1\", \"phase2\"]  # e.g., \"Reach & Grasp\" vs. \"Lift & Hold\"\n",
    "\n",
    "# Output directory for saving results\n",
    "OUTPUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q3 Anticipatory Information at Lift Onset\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 1) Helper Functions\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def trial_info(trial_number):\n",
    "    \"\"\"\n",
    "    Returns metadata about each trial, including whether the weight distribution\n",
    "    is Known or Unknown (field 'knowledge' == 'Yes' or 'No').\n",
    "    \"\"\"\n",
    "    protocol = {\n",
    "        1:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"No\"),\n",
    "        2:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"Yes\"),\n",
    "        3:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"No\"),\n",
    "        4:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"Yes\"),\n",
    "        5:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        6:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        7:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        8:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        9:  (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"No\"),\n",
    "        10: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"Yes\"),\n",
    "        11: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        12: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        13: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        14: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        15: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        16: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        17: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        18: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        19: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        20: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        21: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        22: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        23: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"No\"),\n",
    "        24: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"Yes\"),\n",
    "    }\n",
    "    if trial_number not in protocol:\n",
    "        return None\n",
    "    tup = protocol[trial_number]\n",
    "    return {\n",
    "        'grasp_type':   tup[0],\n",
    "        'handle_type':  tup[1],\n",
    "        'weight_kg':    tup[2],\n",
    "        'lever_side':   tup[3],\n",
    "        'knowledge':    tup[4],  # 'Yes' => Known, 'No' => Unknown\n",
    "    }\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    denom = np.linalg.norm(vec_a) * np.linalg.norm(vec_b)\n",
    "    if denom < 1e-12:\n",
    "        return np.nan\n",
    "    return np.dot(vec_a, vec_b) / denom\n",
    "\n",
    "def load_synergy_factors_full(participant_dir, trial_idx, phase_name):\n",
    "    synergy_dir = os.path.join(participant_dir, \"Extracted Synergies\")\n",
    "    prefix = f\"trial_{trial_idx:02d}_{phase_name}\"\n",
    "    w_file = os.path.join(synergy_dir, prefix + \"_W.npy\")\n",
    "    h_file = os.path.join(synergy_dir, prefix + \"_H.npy\")\n",
    "    if not (os.path.exists(w_file) and os.path.exists(h_file)):\n",
    "        return None, None\n",
    "    W = np.load(w_file)\n",
    "    H = np.load(h_file)\n",
    "    return W, H\n",
    "\n",
    "def load_synergy_factors_liftonset(participant_dir, trial_idx, phase_name):\n",
    "    synergy_dir = os.path.join(participant_dir, \"Synergies at Lift-Onset\")\n",
    "    prefix = f\"trial_{trial_idx:02d}_{phase_name}_liftonset\"\n",
    "    w_file = os.path.join(synergy_dir, prefix + \"_W.npy\")\n",
    "    h_file = os.path.join(synergy_dir, prefix + \"_H.npy\")\n",
    "    if not (os.path.exists(w_file) and os.path.exists(h_file)):\n",
    "        return None, None\n",
    "    W = np.load(w_file)\n",
    "    H = np.load(h_file)\n",
    "    return W, H\n",
    "\n",
    "def match_synergies_greedy(W1, W2):\n",
    "    n_s1 = W1.shape[1]\n",
    "    n_s2 = W2.shape[1]\n",
    "    if n_s1 != n_s2:\n",
    "        return []\n",
    "\n",
    "    unmatched1 = list(range(n_s1))\n",
    "    unmatched2 = list(range(n_s2))\n",
    "    matched_pairs = []\n",
    "\n",
    "    while unmatched1 and unmatched2:\n",
    "        best_sim = -np.inf\n",
    "        best_pair = (None, None)\n",
    "        for i in unmatched1:\n",
    "            for j in unmatched2:\n",
    "                sim = cosine_similarity(W1[:, i], W2[:, j])\n",
    "                if not np.isnan(sim) and sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_pair = (i, j)\n",
    "        if best_pair == (None, None):\n",
    "            break\n",
    "        matched_pairs.append(best_pair)\n",
    "        unmatched1.remove(best_pair[0])\n",
    "        unmatched2.remove(best_pair[1])\n",
    "\n",
    "    return matched_pairs\n",
    "\n",
    "def sig_label(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 2) Main Analysis: Compare Full Phase Correlation vs. Lift-Onset Correlation\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def compare_phase_correlation():\n",
    "    results = []\n",
    "\n",
    "    for pid in PARTICIPANTS:\n",
    "        participant_str = f\"P({pid})\"\n",
    "        participant_dir = os.path.join(BASE_DIR, participant_str)\n",
    "        if not os.path.isdir(participant_dir):\n",
    "            print(f\"[WARN] Missing folder for {participant_str}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        for trial_idx in range(1, 25):\n",
    "            # Load synergy factors for the FULL phases\n",
    "            W1_full, _ = load_synergy_factors_full(participant_dir, trial_idx, PHASES[0])\n",
    "            W2_full, _ = load_synergy_factors_full(participant_dir, trial_idx, PHASES[1])\n",
    "\n",
    "            # Load synergy factors for the LIFT-ONSET\n",
    "            W1_onset, _ = load_synergy_factors_liftonset(participant_dir, trial_idx, PHASES[0])\n",
    "            W2_onset, _ = load_synergy_factors_liftonset(participant_dir, trial_idx, PHASES[1])\n",
    "\n",
    "            if (W1_full is None or W2_full is None or \n",
    "                W1_onset is None or W2_onset is None):\n",
    "                continue\n",
    "\n",
    "            pairs_full = match_synergies_greedy(W1_full, W2_full)\n",
    "            pairs_onset = match_synergies_greedy(W1_onset, W2_onset)\n",
    "\n",
    "            if not pairs_full or not pairs_onset:\n",
    "                continue\n",
    "\n",
    "            corr_vals_full = []\n",
    "            for (i1, i2) in pairs_full:\n",
    "                vec1 = W1_full[:, i1]\n",
    "                vec2 = W2_full[:, i2]\n",
    "                r, _ = pearsonr(vec1, vec2)\n",
    "                corr_vals_full.append(r)\n",
    "            mean_corr_full = np.mean(corr_vals_full) if corr_vals_full else np.nan\n",
    "\n",
    "            corr_vals_onset = []\n",
    "            for (i1, i2) in pairs_onset:\n",
    "                vec1 = W1_onset[:, i1]\n",
    "                vec2 = W2_onset[:, i2]\n",
    "                r, _ = pearsonr(vec1, vec2)\n",
    "                corr_vals_onset.append(r)\n",
    "            mean_corr_onset = np.mean(corr_vals_onset) if corr_vals_onset else np.nan\n",
    "\n",
    "            results.append({\n",
    "                'participant': pid,\n",
    "                'trial': trial_idx,\n",
    "                'mean_corr_full': mean_corr_full,\n",
    "                'mean_corr_liftonset': mean_corr_onset\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    if df_results.empty:\n",
    "        print(\"[INFO] No data found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    out_csv = os.path.join(OUTPUT_DIR, \"mean_correlation_full_vs_liftonset.csv\")\n",
    "    df_results.to_csv(out_csv, index=False)\n",
    "    print(f\"[INFO] Saved raw correlation comparison to {out_csv}\")\n",
    "\n",
    "    df_clean = df_results.dropna(subset=['mean_corr_full', 'mean_corr_liftonset'])\n",
    "    t_stat, p_val = ttest_rel(df_clean['mean_corr_full'], df_clean['mean_corr_liftonset'])\n",
    "    star_label = sig_label(p_val)\n",
    "\n",
    "    print(\"=== Paired T-Test: Full Phase vs. Lift-Onset Phase ===\")\n",
    "    print(f\"T-statistic = {t_stat:.3f}, p-value = {p_val:.6f} => {star_label}\")\n",
    "\n",
    "    df_melt = df_clean.melt(\n",
    "        id_vars=['participant', 'trial'],\n",
    "        value_vars=['mean_corr_full', 'mean_corr_liftonset'],\n",
    "        var_name='phase_window', \n",
    "        value_name='corr'\n",
    "    )\n",
    "\n",
    "    df_melt['phase_window'] = df_melt['phase_window'].map({\n",
    "        'mean_corr_full': 'Full Phase Correlation',\n",
    "        'mean_corr_liftonset': 'Lift-Onset Correlation'\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.boxplot(x='phase_window', y='corr', data=df_melt, palette=\"Set2\")\n",
    "    sns.swarmplot(x='phase_window', y='corr', data=df_melt, color='k', alpha=0.6)\n",
    "    plt.title(\"Comparison of Synergy Correlation between Phases\", fontsize=15)\n",
    "    plt.ylabel(\"Mean Pearson Correlation\", fontsize=15)\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    # Set fontsize of x-axis tick labels to 14\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # Calculate position for significance annotation between boxes\n",
    "    full_data = df_melt[df_melt['phase_window'] == 'Full Phase Correlation']['corr']\n",
    "    liftonset_data = df_melt[df_melt['phase_window'] == 'Lift-Onset Correlation']['corr']\n",
    "    max_val = max(full_data.max(), liftonset_data.max())\n",
    "    offset = (df_melt['corr'].max() - df_melt['corr'].min()) * 0.05\n",
    "\n",
    "    # Place text at x=0.5 (middle between boxes) and y-value above the highest box\n",
    "    plt.text(0.5, max_val - offset, star_label, ha='center', va='bottom', fontsize=15, color='red')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_plot = os.path.join(OUTPUT_DIR, \"boxplot_full_vs_liftonset.png\")\n",
    "    plt.savefig(out_plot, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved boxplot comparing Full vs. Lift-Onset to {out_plot}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 3) Execute Analysis\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    compare_phase_correlation()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Mapping of Channels to Muscle and Kinematic Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) User Definitions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Participants to process\n",
    "PARTICIPANTS = [\"P(3)\"]  # Processing only Participant 1\n",
    "\n",
    "# Define all trial numbers (1-24)\n",
    "TRIAL_NUMBERS = list(range(1, 25))\n",
    "\n",
    "# Grasp types and weight conditions derived from trial_info\n",
    "GRASP_TYPES = [\n",
    "    \"Precision Grasp (Four Fingers and Thumb)\",\n",
    "    \"Lateral Pinch Grasp\",\n",
    "    \"Ball Grasp\",\n",
    "    \"Precision Grasp (Thumb and Index)\",\n",
    "    \"Disc Grip\",\n",
    "    \"Power Bar Grasp\"\n",
    "]\n",
    "\n",
    "WEIGHT_CONDITIONS = [0.25, 0.50]  # in kilograms\n",
    "\n",
    "# Directories for synergy W files and output results\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "OUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q5 Biomechanical Linkages\\P(3)\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "NUM_CHANNELS = 180\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Define Muscle/Finger Groups\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define muscle and finger groups with zero-based channel indices\n",
    "MUSCLE_MAP_FOREARM = {\n",
    "    \"Brachioradialis Supinator\": [0, 1, 2, 13, 14, 15, 26, 27, 28, 39, 40, 41],\n",
    "    \"Pronator Teres\": [3, 4, 5, 16, 17, 18, 29, 30, 31, 42, 43, 44],\n",
    "    \"Flexor Digitorum Superficialis\": [6, 7, 8, 19, 20, 21, 32, 33, 34, 45, 46, 47],\n",
    "    \"Flexor Carpi Ulnaris\": [9, 10, 11, 12, 22, 23, 24, 25, 35, 36, 37, 38, 48, 49, 50, 51],\n",
    "}\n",
    "\n",
    "# Updated Thenar Muscle Groups based on final allocation\n",
    "MUSCLE_MAP_THENAR = {\n",
    "    \"Abductor Pollicis Brevis\": (\n",
    "        list(range(52, 64))    # 52-63\n",
    "        + list(range(66, 76))  # 66-75\n",
    "        + list(range(80, 88))  # 80-87\n",
    "        + list(range(96, 100)) # 96-99\n",
    "    ),\n",
    "    \"Flexor Pollicis Brevis\": (\n",
    "        list(range(64, 66))    # 64-65\n",
    "        + list(range(76, 80))  # 76-79\n",
    "        + list(range(88, 96))  # 88-95\n",
    "        + list(range(100, 112))# 100-111\n",
    "    ),\n",
    "}\n",
    "\n",
    "MYO_CHANNELS = {\n",
    "    \"ECU_myo\": [112],\n",
    "    \"EDC_myo\": [113],\n",
    "    \"ECR_myo\": [114],\n",
    "    \"Biceps\":  [115],\n",
    "    \"Triceps\": [116],\n",
    "}\n",
    "\n",
    "# Corrected Kinematic Mapping: Channels 117-179 (63 channels)\n",
    "KINEMATIC_MAP = {\n",
    "    \"Wrist\": list(range(117, 120)),           # Channels 117,118,119\n",
    "    \"Thumb\": list(range(120, 132)),           # Channels 120-131\n",
    "    \"Index Finger\": list(range(132, 144)),    # Channels 132-143\n",
    "    \"Middle Finger\": list(range(144, 156)),   # Channels 144-155\n",
    "    \"Ring Finger\": list(range(156, 168)),     # Channels 156-167\n",
    "    \"Little Finger\": list(range(168, 180)),   # Channels 168-179\n",
    "}\n",
    "\n",
    "# Combine all groups into a single dictionary without overlap\n",
    "GROUPS = {}\n",
    "\n",
    "# Add Forearm Muscle Groups\n",
    "for group_name, channels in MUSCLE_MAP_FOREARM.items():\n",
    "    GROUPS[group_name] = channels\n",
    "\n",
    "# Add Thenar Muscle Groups\n",
    "for group_name, channels in MUSCLE_MAP_THENAR.items():\n",
    "    GROUPS[group_name] = channels\n",
    "\n",
    "# Add Myo Channels\n",
    "for group_name, channels in MYO_CHANNELS.items():\n",
    "    GROUPS[group_name] = channels\n",
    "\n",
    "# Add Kinematic Groups (Channels 117-179)\n",
    "for group_name, channels in KINEMATIC_MAP.items():\n",
    "    GROUPS[group_name] = channels\n",
    "\n",
    "# Verify that all channel indices are within bounds\n",
    "for group, channels in GROUPS.items():\n",
    "    for ch in channels:\n",
    "        if ch < 0 or ch >= NUM_CHANNELS:\n",
    "            raise ValueError(f\"Channel index {ch} in group '{group}' is out of bounds.\")\n",
    "\n",
    "# Verify no overlapping channels\n",
    "all_channels = [ch for groups in GROUPS.values() for ch in groups]\n",
    "if len(all_channels) != len(set(all_channels)):\n",
    "    overlapping = set([ch for ch in all_channels if all_channels.count(ch) > 1])\n",
    "    raise ValueError(f\"Overlapping channels detected: {overlapping}\")\n",
    "else:\n",
    "    print(\"[INFO] No overlapping channels detected.\")\n",
    "\n",
    "# Define placeholder names for all channels (can be customized)\n",
    "ROW_NAMES = [f\"Ch{ch+1}\" for ch in range(NUM_CHANNELS)]  # \"Ch1\" to \"Ch180\"\n",
    "assert len(ROW_NAMES) == NUM_CHANNELS\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Loading Synergy W for Each Participant/Trial (Phase 2 Only)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_synergy_w_phase2(base_dir, participant, trial_idx):\n",
    "    \"\"\"\n",
    "    Loads the synergy matrix W for a given participant and trial from phase2.\n",
    "\n",
    "    File naming pattern: trial_<trial_number>_phase2_W.npy\n",
    "    Example: trial_01_phase2_W.npy\n",
    "\n",
    "    Parameters:\n",
    "        base_dir (str): Base directory path where synergy files are stored.\n",
    "        participant (str): Participant identifier (e.g., \"P(1)\").\n",
    "        trial_idx (int): Trial number (1-24).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray or None: Synergy matrix W if loaded successfully, else None.\n",
    "    \"\"\"\n",
    "    # Construct the file name based on trial index and phase2\n",
    "    file_name = f\"trial_{trial_idx:02d}_phase2_W.npy\"\n",
    "    w_path = os.path.join(base_dir, participant, \"Extracted Synergies\", file_name)\n",
    "\n",
    "    if not os.path.exists(w_path):\n",
    "        print(f\"[WARN] Synergy W not found: {w_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        W = np.load(w_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load {w_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if W.shape[0] != NUM_CHANNELS:\n",
    "        print(f\"[WARN] Synergy mismatch shape={W.shape} in {w_path}, skipping.\")\n",
    "        return None\n",
    "\n",
    "    return W  # shape => (180, n_local_synergies)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Pool Synergy Matrix by Muscle/Finger Groups (Excluding Zeroed Channels)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def pool_synergies_by_groups(W, group_dict):\n",
    "    \"\"\"\n",
    "    Pools the synergy matrix W by averaging activations within each muscle/finger group,\n",
    "    excluding channels that are zeroed out (all-zero activations). For kinematic groups,\n",
    "    takes the absolute value of activations before averaging.\n",
    "\n",
    "    Parameters:\n",
    "        W (np.ndarray): Synergy matrix of shape (num_channels, num_synergies).\n",
    "        group_dict (dict): Dictionary mapping group names to lists of channel indices (zero-based).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - np.ndarray: Pooled synergy matrix of shape (num_groups, num_synergies).\n",
    "            - list: List of group names corresponding to the pooled matrix.\n",
    "    \"\"\"\n",
    "    num_synergies = W.shape[1]\n",
    "    pooled_data = []\n",
    "    pooled_labels = []\n",
    "\n",
    "    for group_name, ch_idxs in group_dict.items():\n",
    "        if not ch_idxs:\n",
    "            continue\n",
    "        subW = W[ch_idxs, :]  # (num_channels_in_group, num_synergies)\n",
    "\n",
    "        # Identify channels that are not all zero\n",
    "        non_zero_channels = ~np.all(subW == 0, axis=1)\n",
    "        num_non_zero = np.sum(non_zero_channels)\n",
    "\n",
    "        if num_non_zero == 0:\n",
    "            print(f\"[WARN] All channels in group '{group_name}' are zeroed out. Setting pooled synergy to zero.\")\n",
    "            mean_vec = np.zeros(num_synergies)\n",
    "        else:\n",
    "            filtered_subW = subW[non_zero_channels, :]  # Exclude zeroed channels\n",
    "            \n",
    "            # If the group is a kinematic group, take the absolute value\n",
    "            if group_name in KINEMATIC_MAP.keys():\n",
    "                filtered_subW = np.abs(filtered_subW)\n",
    "                print(f\"[INFO] Applied absolute value to kinematic group '{group_name}'.\")\n",
    "\n",
    "            mean_vec = np.mean(filtered_subW, axis=0)  # Average only non-zero channels\n",
    "\n",
    "        # Debugging: Print the mean vector for kinematic groups\n",
    "        if group_name in KINEMATIC_MAP.keys():\n",
    "            print(f\"[DEBUG] Group: {group_name}, Mean Synergy: {mean_vec}\")\n",
    "\n",
    "        pooled_data.append(mean_vec)\n",
    "        pooled_labels.append(group_name)\n",
    "\n",
    "    if not pooled_data:\n",
    "        print(\"[WARN] No groups found to pool.\")\n",
    "        return None, None\n",
    "\n",
    "    W_pooled = np.vstack(pooled_data)  # (#groups, num_synergies)\n",
    "    return W_pooled, pooled_labels\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Plot Synergy Bars - Enhanced Readability (Revised Function)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_synergy_bars(W_pooled, group_labels, out_fig=None, title=\"\", group_categories=None):\n",
    "    \"\"\"\n",
    "    Plots bar charts for each synergy based on the pooled synergy matrix with enhanced readability.\n",
    "    Excludes zeroed channels from averaging.\n",
    "\n",
    "    Parameters:\n",
    "        W_pooled (np.ndarray): Pooled synergy matrix of shape (num_groups, num_synergies).\n",
    "        group_labels (list): List of group names corresponding to W_pooled's rows.\n",
    "        out_fig (str, optional): Path to save the figure. If None, displays the plot.\n",
    "        title (str, optional): Title for the plot.\n",
    "        group_categories (dict, optional): Dictionary mapping group names to categories for color-coding.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    num_groups, num_syn = W_pooled.shape\n",
    "\n",
    "    # Define categories and assign colors\n",
    "    if group_categories:\n",
    "        unique_categories = list(set(group_categories.values()))\n",
    "        # Use a softer palette, e.g., 'Set2' or 'Pastel1'\n",
    "        palette = sns.color_palette(\"Set2\", len(unique_categories))\n",
    "        category_color_map = dict(zip(unique_categories, palette))\n",
    "        group_colors = [category_color_map[group_categories.get(g, 'Other')] for g in group_labels]\n",
    "    else:\n",
    "        group_colors = ['skyblue'] * num_groups  # Default color\n",
    "\n",
    "    # Determine the grid size for subplots (single column)\n",
    "    cols = 1  # Single column\n",
    "    rows = num_syn  # One row per synergy\n",
    "\n",
    "    # Increase figure size based on the number of synergies\n",
    "    fig_width = 18  # Wider figure for better visibility\n",
    "    fig_height = 4 * rows  # Taller figure to accommodate larger text\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(fig_width, fig_height), sharey=True)\n",
    "\n",
    "    # If there's only one synergy, axes is not a list\n",
    "    if num_syn == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i in range(num_syn):\n",
    "        ax = axes[i]\n",
    "        synergy_vec = W_pooled[:, i]\n",
    "        x_positions = np.arange(num_groups)\n",
    "\n",
    "        bars = ax.bar(x_positions, synergy_vec, color=group_colors, alpha=0.9)\n",
    "        ax.set_title(f\"Synergy {i+1}\", fontsize=24)\n",
    "\n",
    "        # Only set x-axis labels for the bottom subplot\n",
    "        if i == num_syn - 1:\n",
    "            ax.set_xticks(x_positions)\n",
    "            ax.set_xticklabels(group_labels, rotation=45, ha='right', fontsize=20)\n",
    "            ax.set_xlabel(\"Muscle Groups\", fontsize=22)\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Mean Activation\", fontsize=18)\n",
    "\n",
    "        # Increase tick label sizes\n",
    "        ax.tick_params(axis='y', labelsize=21)\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Create legend if group categories are provided\n",
    "    if group_categories:\n",
    "        legend_elements = [Patch(facecolor=category_color_map[cat], label=cat) for cat in unique_categories]\n",
    "        fig.legend(handles=legend_elements, loc='upper left', title='Muscle Categories',\n",
    "                   fontsize=20, title_fontsize=22, frameon=True)\n",
    "\n",
    "    plt.suptitle(title, fontsize=26, y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    if out_fig:\n",
    "        plt.savefig(out_fig, dpi=700, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"[INFO] Saved synergy bar chart => {out_fig}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Verification Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def check_synergy_signs(W_pooled, group_labels):\n",
    "    \"\"\"\n",
    "    Checks and prints whether each group has negative synergy values.\n",
    "\n",
    "    Parameters:\n",
    "        W_pooled (np.ndarray): Pooled synergy matrix of shape (num_groups, num_synergies).\n",
    "        group_labels (list): List of group names corresponding to W_pooled's rows.\n",
    "    \"\"\"\n",
    "    for idx, group in enumerate(group_labels):\n",
    "        synergy = W_pooled[idx]\n",
    "        has_negative = np.any(synergy < 0)\n",
    "        has_positive = np.any(synergy > 0)\n",
    "        if has_negative and has_positive:\n",
    "            status = \"Mixed (Both Positive and Negative)\"\n",
    "        elif has_negative:\n",
    "            status = \"Exclusively Negative\"\n",
    "        elif has_positive:\n",
    "            status = \"Exclusively Positive\"\n",
    "        else:\n",
    "            status = \"All Zero\"\n",
    "        print(f\"[INFO] Group: {group}, Synergy Sign Status: {status}\")\n",
    "\n",
    "def plot_synergy_distributions(W_pooled, group_labels, title=\"Synergy Distributions\"):\n",
    "    \"\"\"\n",
    "    Plots the distribution of synergy values for each group.\n",
    "\n",
    "    Parameters:\n",
    "        W_pooled (np.ndarray): Pooled synergy matrix of shape (num_groups, num_synergies).\n",
    "        group_labels (list): List of group names corresponding to W_pooled's rows.\n",
    "        title (str, optional): Title for the plot.\n",
    "    \"\"\"\n",
    "    for idx, group in enumerate(group_labels):\n",
    "        synergy = W_pooled[idx]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.histplot(synergy, bins=30, kde=True, color='skyblue')\n",
    "        plt.title(f\"Distribution of Synergy Values for {group}\")\n",
    "        plt.xlabel(\"Synergy Activation\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.axvline(0, color='red', linestyle='--', linewidth=1)\n",
    "        plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) Trial Information\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def trial_info(trial_number):\n",
    "    \"\"\"\n",
    "    Returns metadata about each trial, including whether the weight distribution\n",
    "    is Known or Unknown (field 'knowledge' == 'Yes' or 'No').\n",
    "\n",
    "    Parameters:\n",
    "        trial_number (int): Trial number (1-24).\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Dictionary containing trial metadata or None if invalid trial number.\n",
    "    \"\"\"\n",
    "    protocol = {\n",
    "        1:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"No\"),\n",
    "        2:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"Yes\"),\n",
    "        3:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"No\"),\n",
    "        4:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"Yes\"),\n",
    "        5:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        6:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        7:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        8:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        9:  (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"No\"),\n",
    "        10: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"Yes\"),\n",
    "        11: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        12: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        13: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        14: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        15: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        16: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        17: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        18: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        19: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        20: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        21: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        22: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        23: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"No\"),\n",
    "        24: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"Yes\"),\n",
    "    }\n",
    "    if trial_number not in protocol:\n",
    "        return None\n",
    "    tup = protocol[trial_number]\n",
    "    return {\n",
    "        'grasp_type':   tup[0],\n",
    "        'handle_type':  tup[1],\n",
    "        'weight_kg':    tup[2],\n",
    "        'lever_side':   tup[3],\n",
    "        'knowledge':    tup[4],  # 'Yes' => Known, 'No' => Unknown\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8) Main Script: Gather Synergy Columns for Participant 1, Map, Average, Plot\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    # Define group categories for color-coding\n",
    "    group_categories_map = {}\n",
    "    # Forearm Muscles\n",
    "    forearm_muscle_groups = list(MUSCLE_MAP_FOREARM.keys())\n",
    "    for group in forearm_muscle_groups:\n",
    "        group_categories_map[group] = 'Forearm Muscles'\n",
    "    # Thenar Muscles\n",
    "    thenar_muscle_groups = list(MUSCLE_MAP_THENAR.keys())\n",
    "    for group in thenar_muscle_groups:\n",
    "        group_categories_map[group] = 'Thenar Muscles'\n",
    "    # Myo Channels\n",
    "    myo_groups = list(MYO_CHANNELS.keys())\n",
    "    for group in myo_groups:\n",
    "        group_categories_map[group] = 'Myo Channels'\n",
    "    # Kinematic Groups\n",
    "    kinematic_groups = list(KINEMATIC_MAP.keys())\n",
    "    for group in kinematic_groups:\n",
    "        group_categories_map[group] = 'Kinematic Groups'\n",
    "\n",
    "    # Step 1: Group trials by condition (excluding 'knowledge')\n",
    "    conditions = {}\n",
    "    for trial_num in TRIAL_NUMBERS:\n",
    "        info = trial_info(trial_num)\n",
    "        if not info:\n",
    "            print(f\"[WARN] Trial information missing for trial {trial_num}, skipping.\")\n",
    "            continue\n",
    "        # Define condition key excluding 'knowledge'\n",
    "        condition_key = (\n",
    "            info['grasp_type'],\n",
    "            info['handle_type'],\n",
    "            info['weight_kg'],\n",
    "            info['lever_side']\n",
    "        )\n",
    "        if condition_key not in conditions:\n",
    "            conditions[condition_key] = []\n",
    "        conditions[condition_key].append(trial_num)\n",
    "\n",
    "    print(f\"[INFO] Found {len(conditions)} unique conditions.\")\n",
    "\n",
    "    # Step 2: Process each condition\n",
    "    for condition_key, trial_numbers in conditions.items():\n",
    "        grasp_type, handle_type, weight_kg, lever_side = condition_key\n",
    "        condition_name = (\n",
    "            f\"{grasp_type.replace(' ', '_').replace('(', '').replace(')', '').replace('/', '_')}_\"\n",
    "            f\"{weight_kg}kg_\"\n",
    "            f\"{lever_side.replace(' ', '_')}\"\n",
    "        )\n",
    "        print(f\"\\n----- Processing Condition: {condition_name} -----\")\n",
    "\n",
    "        # 1) Gather synergy matrices for all trials of P(1) in this condition (Phase 2 only)\n",
    "        pooled_W_matrices = []\n",
    "        for p in PARTICIPANTS:\n",
    "            for trial_num in trial_numbers:\n",
    "                W = load_synergy_w_phase2(\n",
    "                    BASE_DIR,\n",
    "                    p,\n",
    "                    trial_num\n",
    "                )\n",
    "                if W is None:\n",
    "                    print(f\"[WARN] Missing synergy data for participant {p} in trial {trial_num}, skipping.\")\n",
    "                    continue\n",
    "                pooled_W_matrices.append(W)  # list of (180, n_syn)\n",
    "\n",
    "        if not pooled_W_matrices:\n",
    "            print(\"[WARN] No synergy data found for this condition. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 2) Aggregate synergy matrices across trials by averaging\n",
    "        # First, determine the maximum number of synergies across all W matrices\n",
    "        max_synergies = max(W.shape[1] for W in pooled_W_matrices)\n",
    "        # Initialize a list to hold padded W matrices\n",
    "        padded_W_matrices = []\n",
    "        for W in pooled_W_matrices:\n",
    "            if W.shape[1] < max_synergies:\n",
    "                # Pad with zeros to match the maximum number of synergies\n",
    "                padding = np.zeros((NUM_CHANNELS, max_synergies - W.shape[1]))\n",
    "                W_padded = np.hstack((W, padding))\n",
    "            else:\n",
    "                W_padded = W[:, :max_synergies]  # Truncate if necessary\n",
    "            padded_W_matrices.append(W_padded)\n",
    "\n",
    "        # Convert to a 3D array for averaging\n",
    "        W_stack = np.stack(padded_W_matrices, axis=2)  # shape => (180, max_synergies, num_trials)\n",
    "        W_mean = np.mean(W_stack, axis=2)  # shape => (180, max_synergies)\n",
    "        print(f\"[INFO] Averaged synergy matrix shape: {W_mean.shape}\")\n",
    "\n",
    "        # 3) Pool at muscle and kinematic group level\n",
    "        W_pooled, pooled_labels = pool_synergies_by_groups(W_mean, GROUPS)\n",
    "        if W_pooled is None:\n",
    "            print(\"[WARN] Pooling failed. Skipping plotting.\")\n",
    "            continue\n",
    "\n",
    "        # 4) Assign categories to pooled groups\n",
    "        pooled_categories = {group: group_categories_map.get(group, 'Other') for group in pooled_labels}\n",
    "\n",
    "        # 5) Verify Synergy Signs\n",
    "        check_synergy_signs(W_pooled, pooled_labels)\n",
    "\n",
    "        # 6) Plot Synergy Distributions (optional)\n",
    "        # plot_synergy_distributions(W_pooled, pooled_labels)\n",
    "\n",
    "        # 7) Plot Using the Enhanced Bar Plot\n",
    "        out_name = f\"{condition_name}_pooledSynergies_bars.png\"\n",
    "        out_path = os.path.join(OUT_DIR, out_name)\n",
    "        plot_title = (\n",
    "            f\"{grasp_type} / {weight_kg}kg / {lever_side} Lever\\n\"\n",
    "            f\"=> Pooled Synergies (Phase 2)\"\n",
    "        )\n",
    "        plot_synergy_bars(\n",
    "            W_pooled, \n",
    "            pooled_labels, \n",
    "            out_fig=out_path, \n",
    "            title=plot_title,\n",
    "            group_categories=pooled_categories\n",
    "        )\n",
    "\n",
    "    print(\"\\n----- Done. Check synergy bar charts in:\", OUT_DIR, \"-----\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Task Efficiency and overall Muscle Activation between Known and Unknown Conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Analysis of Phase 2 EMG and OTB Data: Comparing Muscle Activation Between\n",
    "# \"Known\" and \"Unknown\" Task Knowledge Conditions\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0) Global Configuration\n",
    "# -------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Experimental Data\"\n",
    "PARTICIPANTS = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "TRIALS = range(1, 25)  # Trials 1 to 24\n",
    "PHASE = \"phase2\"  # Focus only on Phase 2\n",
    "\n",
    "# Updated Output directory as specified by the user\n",
    "OUTPUT_DIR = r\"C:\\Users\\schmi\\Documents\\Studium\\TUM\\5. Semester\\Masterthesis\\Results Statistical Analysis\\Q6 Task Efficiency by Muscle Activation\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Helper: trial_info\n",
    "# -------------------------------------------------------------------\n",
    "def trial_info(trial_number):\n",
    "    \"\"\"\n",
    "    Returns metadata about each trial, including whether the weight distribution\n",
    "    is Known or Unknown (field 'knowledge' == 'Yes' or 'No').\n",
    "    \"\"\"\n",
    "    protocol = {\n",
    "        1:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"No\"),\n",
    "        2:  (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Left Lever\",  \"Yes\"),\n",
    "        3:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"No\"),\n",
    "        4:  (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Right Lever\", \"Yes\"),\n",
    "        5:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        6:  (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        7:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        8:  (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        9:  (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"No\"),\n",
    "        10: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Back Lever\", \"Yes\"),\n",
    "        11: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        12: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        13: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"No\"),\n",
    "        14: (\"Precision Grasp (Four Fingers and Thumb)\", \"Precision Handle\", 0.25, \"Front Lever\", \"Yes\"),\n",
    "        15: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        16: (\"Lateral Pinch Grasp\", \"Lateral Pinch Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        17: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"No\"),\n",
    "        18: (\"Ball Grasp\", \"Ball Handle\", 0.50, \"Front Lever\", \"Yes\"),\n",
    "        19: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"No\"),\n",
    "        20: (\"Precision Grasp (Thumb and Index)\", \"Precision Handle\", 0.25, \"Back Lever\", \"Yes\"),\n",
    "        21: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"No\"),\n",
    "        22: (\"Disc Grip\", \"Disc Handle\", 0.50, \"Left Lever\", \"Yes\"),\n",
    "        23: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"No\"),\n",
    "        24: (\"Power Bar Grasp\", \"Power Bar Handle\", 0.50, \"Right Lever\", \"Yes\"),\n",
    "    }\n",
    "    if trial_number not in protocol:\n",
    "        return None\n",
    "    tup = protocol[trial_number]\n",
    "    return {\n",
    "        'grasp_type':   tup[0],\n",
    "        'handle_type':  tup[1],\n",
    "        'weight_kg':    tup[2],\n",
    "        'lever_side':   tup[3],\n",
    "        'knowledge':    tup[4],  # 'Yes' => Known, 'No' => Unknown\n",
    "    }\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Helper: Load EMG Data\n",
    "# -------------------------------------------------------------------\n",
    "def load_emg_data(participant_dir, trial_idx):\n",
    "    \"\"\"\n",
    "    Loads the EMG data for a given participant and trial from the \"Synchronized Data split in Phases\" folder.\n",
    "    \n",
    "    Assumes that EMG data is stored as .npy files with the following naming convention:\n",
    "    'match_{trial_idx:02d}_phase2_myo.npy'\n",
    "    \n",
    "    Returns:\n",
    "        emg_data (numpy.ndarray): 2D array with shape (time_points, 5 muscle_channels)\n",
    "        or None if the file does not exist.\n",
    "    \"\"\"\n",
    "    sync_dir = os.path.join(participant_dir, \"Synchronized Data split in Phases\")\n",
    "    emg_file = os.path.join(sync_dir, f\"match_{trial_idx:02d}_phase2_myo.npy\")\n",
    "    if not os.path.exists(emg_file):\n",
    "        return None\n",
    "    emg_data = np.load(emg_file)\n",
    "    return emg_data\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Helper: Load OTB Data\n",
    "# -------------------------------------------------------------------\n",
    "def load_otb_data(participant_dir, trial_idx):\n",
    "    \"\"\"\n",
    "    Loads the OTB data for a given participant and trial from the \"Synchronized Data split in Phases\" folder.\n",
    "    \n",
    "    Assumes that OTB data is stored as .npy files with the following naming convention:\n",
    "    'match_{trial_idx:02d}_phase2_otb.npy'\n",
    "    \n",
    "    Returns:\n",
    "        otb_data (numpy.ndarray): 2D array with shape (time_points, 112 channels)\n",
    "        or None if the file does not exist.\n",
    "    \"\"\"\n",
    "    sync_dir = os.path.join(participant_dir, \"Synchronized Data split in Phases\")\n",
    "    otb_file = os.path.join(sync_dir, f\"match_{trial_idx:02d}_phase2_otb.npy\")\n",
    "    if not os.path.exists(otb_file):\n",
    "        return None\n",
    "    otb_data = np.load(otb_file)\n",
    "    return otb_data\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Main Analysis: Phase 2 EMG and OTB Data Comparison\n",
    "# -------------------------------------------------------------------\n",
    "def emg_otb_activation_analysis():\n",
    "    \"\"\"\n",
    "    Analyzes Phase 2 EMG and OTB data to determine if task knowledge leads to higher muscle efficiency,\n",
    "    i.e., lower muscle activation during the manipulation task.\n",
    "    \n",
    "    Steps:\n",
    "        1. Iterates over participants and trials.\n",
    "        2. Loads EMG and OTB data for Phase 2.\n",
    "        3. Computes average activation over time and across all muscle channels for both EMG and OTB.\n",
    "        4. Aggregates data by participant and condition.\n",
    "        5. Performs paired t-tests between Known and Unknown conditions for both EMG and OTB.\n",
    "        6. Generates visualizations (box plots) and saves them.\n",
    "        7. Calculates percentage decrease in activation.\n",
    "        8. Saves aggregated data, statistical results, and percentage decrease as CSV files.\n",
    "    \"\"\"\n",
    "    activation_rows = []\n",
    "    \n",
    "    # ---- Gather EMG and OTB Data from All Participants & Trials ----\n",
    "    for pid in PARTICIPANTS:\n",
    "        participant_str = f\"P({pid})\"\n",
    "        participant_dir = os.path.join(BASE_DIR, participant_str)\n",
    "        if not os.path.isdir(participant_dir):\n",
    "            print(f\"[WARN] Missing folder for {participant_str}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n=== Analyzing {participant_str} ===\")\n",
    "        \n",
    "        for trial_idx in TRIALS:\n",
    "            meta = trial_info(trial_idx)\n",
    "            if meta is None:\n",
    "                print(f\"[INFO] Trial {trial_idx} has no metadata. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            knowledge_flag = meta['knowledge']  # \"Yes\" => Known, \"No\" => Unknown\n",
    "            condition = \"Known\" if knowledge_flag == \"Yes\" else \"Unknown\"\n",
    "            \n",
    "            # Load EMG data\n",
    "            emg_data = load_emg_data(participant_dir, trial_idx)\n",
    "            if emg_data is None:\n",
    "                print(f\"[INFO] Missing EMG data for Trial {trial_idx}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Load OTB data\n",
    "            otb_data = load_otb_data(participant_dir, trial_idx)\n",
    "            if otb_data is None:\n",
    "                print(f\"[INFO] Missing OTB data for Trial {trial_idx}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Verify EMG data shape\n",
    "            if emg_data.ndim != 2 or emg_data.shape[1] != 5:\n",
    "                print(f\"[WARN] Unexpected EMG data shape for Trial {trial_idx}: {emg_data.shape}. Expected (time_points, 5). Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Verify OTB data shape\n",
    "            if otb_data.ndim != 2 or otb_data.shape[1] != 112:\n",
    "                print(f\"[WARN] Unexpected OTB data shape for Trial {trial_idx}: {otb_data.shape}. Expected (time_points, 112). Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Ensure both datasets have the same number of time points\n",
    "            if emg_data.shape[0] != otb_data.shape[0]:\n",
    "                print(f\"[WARN] Mismatched time points for Trial {trial_idx}: EMG {emg_data.shape[0]}, OTB {otb_data.shape[0]}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Concatenate EMG and OTB data along the channel axis\n",
    "            combined_data = np.concatenate((emg_data, otb_data), axis=1)  # Shape: (time_points, 117 channels)\n",
    "            \n",
    "            # Compute average activation across time and all muscle channels\n",
    "            avg_activation = combined_data.mean()  # Single scalar value\n",
    "            \n",
    "            # Append to rows\n",
    "            activation_rows.append({\n",
    "                'participant': pid,\n",
    "                'trial_idx': trial_idx,\n",
    "                'condition': condition,      # 'Known' or 'Unknown'\n",
    "                'avg_activation': avg_activation\n",
    "            })\n",
    "    \n",
    "    # ---- Convert to DataFrame & Save Raw Data ----\n",
    "    emg_otb_df_raw = pd.DataFrame(activation_rows)\n",
    "    raw_csv = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_activation_raw.csv\")\n",
    "    emg_otb_df_raw.to_csv(raw_csv, index=False)\n",
    "    print(f\"\\n[INFO] Saved raw EMG and OTB activation data to {raw_csv}\")\n",
    "    \n",
    "    # ---- Aggregation: Average Activation per Participant and Condition ----\n",
    "    aggregated = emg_otb_df_raw.groupby(['participant', 'condition']).agg(\n",
    "        avg_activation=('avg_activation', 'mean')\n",
    "    ).reset_index()\n",
    "    agg_csv = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_activation_agg.csv\")\n",
    "    aggregated.to_csv(agg_csv, index=False)\n",
    "    print(f\"[INFO] Saved aggregated EMG and OTB activation data to {agg_csv}\")\n",
    "    \n",
    "    # ---- Pivot for Paired T-Tests ----\n",
    "    pivot = aggregated.pivot(index='participant', columns='condition', values='avg_activation').reset_index()\n",
    "    \n",
    "    # Ensure both conditions are present\n",
    "    pivot = pivot.dropna()\n",
    "    \n",
    "    # ---- Perform Paired T-Tests ----\n",
    "    known = pivot['Known']\n",
    "    unknown = pivot['Unknown']\n",
    "    t_stat, p_val = ttest_rel(known, unknown)\n",
    "    print(f\"\\nPaired T-Test Results:\")\n",
    "    print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n",
    "    \n",
    "    # ---- Add Significance Label ----\n",
    "    def significance_label(p):\n",
    "        if p <= 0.001:\n",
    "            return '***'\n",
    "        elif p <= 0.01:\n",
    "            return '**'\n",
    "        elif p <= 0.05:\n",
    "            return '*'\n",
    "        else:\n",
    "            return 'ns'\n",
    "    \n",
    "    sig_label = significance_label(p_val)\n",
    "    \n",
    "    # ---- Calculate Percentage Decrease ----\n",
    "    # Percentage Decrease = ((Unknown - Known) / Unknown) * 100\n",
    "    percentage_decrease = ((unknown - known) / unknown) * 100\n",
    "    \n",
    "    # Append to DataFrame\n",
    "    pivot['percentage_decrease'] = percentage_decrease\n",
    "    \n",
    "    # Calculate mean and std of percentage decrease\n",
    "    mean_decrease = percentage_decrease.mean()\n",
    "    std_decrease = percentage_decrease.std()\n",
    "    \n",
    "    print(f\"\\nPercentage Decrease in Activation (Known vs. Unknown): {mean_decrease:.2f}% ± {std_decrease:.2f}%\")\n",
    "    \n",
    "    # ---- Save T-Test Results ----\n",
    "    ttest_results = pd.DataFrame({\n",
    "        'Statistic': ['t-statistic', 'p-value'],\n",
    "        'Value': [f\"{t_stat:.3f}\", f\"{p_val:.3f}\"],\n",
    "        'Significance': [sig_label, sig_label]\n",
    "    })\n",
    "    ttest_csv = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_paired_ttest.csv\")\n",
    "    ttest_results.to_csv(ttest_csv, index=False)\n",
    "    print(f\"[INFO] Saved paired t-test results to {ttest_csv}\")\n",
    "    \n",
    "    # ---- Save Percentage Decrease Data ----\n",
    "    percentage_decrease_df = pivot[['participant', 'Known', 'Unknown', 'percentage_decrease']]\n",
    "    percentage_decrease_csv = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_percentage_decrease.csv\")\n",
    "    percentage_decrease_df.to_csv(percentage_decrease_csv, index=False)\n",
    "    print(f\"[INFO] Saved percentage decrease data to {percentage_decrease_csv}\")\n",
    "    \n",
    "    # ---- Visualization: Box Plot ----\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x='condition', y='avg_activation', data=aggregated, palette='Set2')\n",
    "    sns.stripplot(x='condition', y='avg_activation', data=aggregated, color='black', alpha=0.5)\n",
    "    plt.title('Average EMG and OTB Activation by Condition (Phase 2)')\n",
    "    plt.xlabel('Condition')\n",
    "    plt.ylabel('Average Activation')\n",
    "    \n",
    "    # Annotate significance\n",
    "    max_val = aggregated['avg_activation'].max()\n",
    "    plt.text(0.5, max_val + 0.05*(max_val), sig_label, ha='center', va='bottom', color='red', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_activation_boxplot.png\")\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved EMG and OTB activation box plot to {plot_path}\")\n",
    "    \n",
    "    # ---- Visualization: Percentage Decrease Box Plot ----\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.boxplot(y='percentage_decrease', data=pivot, palette='Set3')\n",
    "    sns.stripplot(y='percentage_decrease', data=pivot, color='black', alpha=0.5)\n",
    "    plt.title('Percentage Decrease in Activation (Known vs. Unknown)')\n",
    "    plt.ylabel('Percentage Decrease (%)')\n",
    "    plt.xlabel('')\n",
    "    \n",
    "    # Annotate significance\n",
    "    plt.text(0.0, pivot['percentage_decrease'].max() + 5, sig_label, ha='center', va='bottom', color='red', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    percentage_plot_path = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_percentage_decrease_boxplot.png\")\n",
    "    plt.savefig(percentage_plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved percentage decrease box plot to {percentage_plot_path}\")\n",
    "    \n",
    "    # ---- Summary Statistics Table and Save as PNG ----\n",
    "    # Create a summary table with average and std for each condition\n",
    "    summary_stats = aggregated.groupby('condition').agg(\n",
    "        Mean_Activation=('avg_activation', 'mean'),\n",
    "        Std_Activation=('avg_activation', 'std')\n",
    "    ).reset_index()\n",
    "    summary_stats = summary_stats.round(3)\n",
    "    \n",
    "    # Rename columns for clarity and brevity\n",
    "    summary_stats.rename(columns={\n",
    "        'condition': 'Condition',\n",
    "        'Mean_Activation': 'Mean Act.',\n",
    "        'Std_Activation': 'Std Act.'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Create a figure for the table\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))  # Adjust size as needed\n",
    "    ax.axis('off')  # Hide the axes\n",
    "    \n",
    "    # Create the table\n",
    "    table = ax.table(cellText=summary_stats.values,\n",
    "                     colLabels=summary_stats.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    \n",
    "    # Customize table appearance\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 1.5)  # Adjust as needed\n",
    "    \n",
    "    # Add a title\n",
    "    plt.title('Summary Statistics of EMG and OTB Activation (Phase 2)', fontsize=12, pad=20)\n",
    "    \n",
    "    # Adjust layout to ensure everything fits\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the table as PNG\n",
    "    summary_table_png = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_summary_statistics.png\")\n",
    "    plt.savefig(summary_table_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Summary statistics table saved as PNG to: {summary_table_png}\")\n",
    "    \n",
    "    # ---- Summary Statistics for Percentage Decrease ----\n",
    "    percentage_summary = pd.DataFrame({\n",
    "        'Mean % Decr.': [mean_decrease],\n",
    "        'Std % Decr.': [std_decrease]\n",
    "    })\n",
    "    percentage_summary = percentage_summary.round(2)\n",
    "    \n",
    "    # Create a figure for the percentage summary table\n",
    "    fig, ax = plt.subplots(figsize=(4, 2))  # Adjust size as needed\n",
    "    ax.axis('off')  # Hide the axes\n",
    "    \n",
    "    # Create the table\n",
    "    table = ax.table(cellText=percentage_summary.values,\n",
    "                     colLabels=percentage_summary.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    \n",
    "    # Customize table appearance\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 1.5)  # Adjust as needed\n",
    "    \n",
    "    # Add a title\n",
    "    plt.title('Percentage Decrease in Activation', fontsize=12, pad=20)\n",
    "    \n",
    "    # Adjust layout to ensure everything fits\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the table as PNG\n",
    "    percentage_summary_png = os.path.join(OUTPUT_DIR, \"phase2_emg_otb_percentage_decrease_summary.png\")\n",
    "    plt.savefig(percentage_summary_png, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Percentage decrease summary table saved as PNG to: {percentage_summary_png}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Main Execution\n",
    "# -------------------------------------------------------------------\n",
    "def main():\n",
    "    emg_otb_activation_analysis()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
